<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-10-27T19:23:54+08:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">This is Jeremy!</title><subtitle>Carpe Diem
</subtitle><author><name>Jeremy Yang</name></author><entry><title type="html">数据编码与演化</title><link href="http://localhost:4000/%E6%95%B0%E6%8D%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E6%BC%94%E5%8C%96.html" rel="alternate" type="text/html" title="数据编码与演化" /><published>2021-10-27T00:00:00+08:00</published><updated>2021-10-27T00:00:00+08:00</updated><id>http://localhost:4000/%E6%95%B0%E6%8D%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E6%BC%94%E5%8C%96</id><content type="html" xml:base="http://localhost:4000/%E6%95%B0%E6%8D%AE%E7%BC%96%E7%A0%81%E4%B8%8E%E6%BC%94%E5%8C%96.html">&lt;h1 id=&quot;数据编码与演化&quot;&gt;数据编码与演化&lt;/h1&gt;

&lt;h2 id=&quot;toc&quot;&gt;TOC&lt;/h2&gt;

&lt;p&gt;应用程序会随时间发生变化，大多数情况下，更改应用程序功能时也需要更改其存储的数据：可能需要捕获新的字段或者记录类型或者以新的方式呈现已有数据。&lt;/p&gt;

&lt;p&gt;对于大型应用系统：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;对于服务器端，可能要滚动更新（分阶段发布），每次将新版本部署到少量节点，看能否正常运行，然后逐步在所有节点更新新的代码。这样新版本部署无需服务暂停，从而支持更频繁的版本发布和更好的演化。&lt;/li&gt;
  &lt;li&gt;对于客户端，只能寄希望于用户，然而他们在一段时间内可能不会更新新的版本。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这意味着&lt;strong&gt;新旧版本的代码和新旧数据格式，可能会同时在系统内共存&lt;/strong&gt;。为了保证兼容性，需要保持双向兼容性：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;向后兼容——新的代码可以读取旧代码编写的数据&lt;/li&gt;
  &lt;li&gt;向前兼容——较旧代码可以读取新代码编写的数据&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;向后兼容不难实现，因为新代码的作者清楚旧代码的编写格式，向前兼容比较难，因为需要旧代码忽略新代码所做的添加。&lt;/p&gt;

&lt;h2 id=&quot;数据编码格式&quot;&gt;数据编码格式&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;内存中，数据保存在对象，结构体，数组，哈希表等数据结构中。（也就是说可以用指针引用之类的）&lt;/li&gt;
  &lt;li&gt;将数据写入文件或者向网络中发送时，必须编码为字节序列。（由于指针对于别的进程没有什么意义，所以使用的数据结构就有所不同）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;从内存中的表示到字节序列的转化称为编码（或序列化），相反的过程叫做解码（或解析，反序列化）。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;语言特定的格式&quot;&gt;语言特定的格式&lt;/h2&gt;

&lt;p&gt;很多编程语言都内置支持将内存中的对象编码为字节序列比如Java有java.io.Serializable 等。但是他们存在问题：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;编码格式和语言绑定，用另一种语言访问很难。&lt;/li&gt;
  &lt;li&gt;为了在相同的对象类型中恢复数据，解码过程要能&lt;strong&gt;实例化任意的类&lt;/strong&gt;。这可能导致一些安全隐患。&lt;/li&gt;
  &lt;li&gt;这些库没有考虑向前兼容和向后兼容的问题。&lt;/li&gt;
  &lt;li&gt;效率问题（编码解码的时间，还有编码结构的大小）。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;json-xml和二进制变体&quot;&gt;JSON XML和二进制变体&lt;/h2&gt;
&lt;p&gt;XML经常被批评过于冗长和不必要的复杂。JSON受欢迎主要由于它在Web浏览器中内置支持，以及简单。CSV很流行，尽管功能很弱。&lt;/p&gt;

&lt;p&gt;JSON,XML,CSV都是文本格式都有着不错的可读性，但是也有问题：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;数字编码有模糊之处：XML 和CSV中无法区分数字和由数字构成的字符串，JSON可以区分数字和字符串但是无法区分整数和浮点数。&lt;/li&gt;
  &lt;li&gt;JSON,XML对Unicode字符串有很好的支持但是不支持二进制字符串（没有字符编码的字符序列）
    - XML和JSON都有可选的模式支持。模式学习和实现比较复杂，而且没有使用这些的应用只能硬编码编码解码的逻辑。
    &lt;ul&gt;
      &lt;li&gt;CSV没有任何模式，所以程序需要定义每行没列的含义。如果应用程序添加新的行和列，则需要手动处理更改。&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;尽管这些数据模式存在缺陷，但是他们也很受欢迎，毕竟过，让不同的组织达成一致的难度通常超过了其他所有问题。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;二进制编码&quot;&gt;二进制编码&lt;/h3&gt;
&lt;p&gt;JSON不像XML那样冗长，但是与二进制格式相比还是占了大量空间。这导致开发了大量的二进制编码用以支持JSON（比如MessagePack和BISON）&lt;/p&gt;

&lt;p&gt;其中一些格式还扩展了数据类型集，但其他格式保持了JSON/XML数据模型不变。特别是他们没有规定模式（schema）所以需要在编码数据时包含所有的对象字段名称。&lt;/p&gt;

&lt;p&gt;一条样本记录&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
	    “username”:”Martin”,
		    “favoriteNumber”:1337,
			    “interests”:[“daydreaming”,”hacking”]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;看一个MessagePack的例子。
  &lt;img src=&quot;https://jeremy0953.github.io/pics/2021-10-27-pic1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- 0x83——表示接下来是包含三个字段（第四位0x03）的对象（高四位0x80）
 - 0xa8——便是接下来是八个字节长度的字符串（高四位0xa0，第四位0x08）
  - 后面是八字节的ASCII的userName
   - 以此类推
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;thrift与protocol-buffers&quot;&gt;Thrift与Protocol Buffers&lt;/h2&gt;

&lt;p&gt;Apache Thrift和Protocol Buffers是基于相同原理的两种二进制编码库。他们都需要模式来编码任意的数据。&lt;/p&gt;

&lt;p&gt;Thrift模式定义&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;struct Person {
	   1: required string  userName,
	      2: optional i64  favoriteNumber,
		     3: optional list&amp;lt;string&amp;gt; interests
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Protocol Buffers等价模式定义&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;message Person {
	  required string user_name  = 1;
	    optional int64 favorite_number  = 2;
		  repeated string interests  = 3;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Thrift有两种不同的二进制编码格式，分别称为BinaryProtocol和CompactProtocol。
下图是BinaryProtocol。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jeremy0953.github.io/pics/2021-10-27-pic2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;与MessagePack相比最大的区别是字段名用字段标签（1，2，3）这些是模式定义中出现的数字，是字段名称的别名，用来指示当前字段。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;CompactProtocol语义上等同于BinaryProtocol。他将字段类型和标签号打包到单字节中，并使用可变长度整数来实现。对于数字1337，不使用全部8字节而是使用两个字节。每个字节的最高位用来指示是否还有更多的字节。

  ![](https://jeremy0953.github.io/pics/2021-10-27-pic3.png)

  最后还有Protocol Buffers
   ![](https://jeremy0953.github.io/pics/2021-10-27-pic4.png)

   最后有一个小细节，模式中每一个字段被标记为了required和optional，但是这段字段如何编码没有任何影响，如果字段设置了required但是字段没有填充，运行时检查将会出现失败。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;字段标签和模式演化&quot;&gt;字段标签和模式演化&lt;/h3&gt;

&lt;p&gt;模式不可避免地需要随着时间而不断变化，称之为模式演化。那么这两种是如何在向前兼容和向后兼容的同时应对模式更改呢？&lt;/p&gt;

&lt;p&gt;一条编码记录指示一组编码字段的拼接，每个字段由其标签号标识并使用数据类型进行注释。如果没有设置字段值则将其从编码的记录中简单地忽略。由此可以看出字段标签（field tag）对于编码数据的含义至关重要。可以轻松更改模式中字段的名称，编码永远不直接引用字段名称，但是不能随便更改字段的标签，否则会导致所有现有编码数据无效。&lt;/p&gt;

&lt;p&gt;添加字段时：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;向前兼容：如果旧代码读新代码写入的数据，如果有他不能识别的标记号码直接忽略就好。&lt;/li&gt;
  &lt;li&gt;向后兼容：每个字段有唯一的标记号码，所以新的代码总是能知道旧数据的标记号码，唯一的细节是如果添加一个新的字段则不能使其成为必需字段（required）因为旧代码不会添加新字段，为了保证向后兼容，在模式的初始部署之后添加的每个字段都必须是可选的或者是有默认值的。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;删除字段就像添加字段一样，不过向前兼容和向后兼容正好相反。这意味着只能删除可选的字段（必填字段永远不能被删除）而且不能输再次使用相同的标签号码（因为可能有写入的数据包含旧的标签号码，该字段必需被新代码忽略）&lt;/p&gt;

&lt;h3 id=&quot;数据类型和模式演化&quot;&gt;数据类型和模式演化&lt;/h3&gt;

&lt;p&gt;如何改变字段的数据类型呢？这是有可能的，但是存在值会丢失或者被截断的风险。&lt;/p&gt;

&lt;h2 id=&quot;avro&quot;&gt;Avro&lt;/h2&gt;

&lt;p&gt;Avro是另一种二进制编码格式，也适用模式来指定编码，有两种模式语言，一种(Avro IDL)用于人工编辑，另一种（基于JSON）更易于机器读取。&lt;/p&gt;

&lt;p&gt;用Avro IDL编写的事例模式如下所示：&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;record Person {
	  string  username;
	    union {null, long}  favoriteNumber = null;
		  array&amp;lt;string&amp;gt; interests;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;该模式的等价JSON表示如下：&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
	  “type”: “record”,
	    “name”: “Person”,
		  “field”: [
		      {“name”: “userName”,  “type”: “string”},
			      {“name”: “favoriteNumber”, “type”:[“null”, “long”], “default”: null},
				      {“name”: “interests”, “type”: {“type”: “array”, “items”: “string”}} 
					    ]
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;首先，注意模式中&lt;strong&gt;没有标签编号&lt;/strong&gt;。如果用这个编码模式表示事例记录，只有32字节，这是所见到的所有编码中最紧凑的。编码字节序列分解如图所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jeremy0953.github.io/pics/2021-10-27-pic5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如图所示，可以看到没有什么标识字段或者数据类型。编码只是由连在一起的一些列值组成。一个字符串只是一个长度前缀后面跟着UTF-8字节流，但是编码数据里面没有告诉你它是一个字符流。它也可以是一个整数，或者其他什么类型，整数使用可变长度编码（与CompactProtocol相同）进行编码。&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; 为了解析，按照他们出现在模式中的顺序遍历这些字段，然后直接采用模式告诉你每个字段的数据类型，意味着读取数据代码使用的模式必需和写入数据使用的模式完全相同。如果不匹配就无法解析。
  
   *那么Avro如何支持编码演化？*
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;写模式与读模式&quot;&gt;写模式与读模式&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	- 写模式：编码应用程序所用的模式（例如可以编译到应用程序中的模式）
	- 读模式：应用程序解码，期望数据所希望的模式（应用程序依赖的模式，应用程序代码都有可能是根据读模式动态生成的）

	Avro的关键思想，**写模式和读模式不一定是完全一模一样**，只需要保持兼容即可，Avro库会自动对比查看写模式和读模式并将数据从写模式转换为读模式来解决差异。

	 例如，如果读写模式的字段顺序不同也没关系，如果读取的代码遇到写模式里有但是读模式没有的就忽略它，如果读模式遇到了需要读但是写模式里面没有的就直接使用默认值。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;模式演化规则&quot;&gt;模式演化规则&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;	   - 向前兼容： 新版本的writer，旧版本的reader
	   - 向后兼容： 旧版本的writer，新版本的reader

	   为了保持兼容性，只能添加和删除有**默认值**的字段。

	   比如读模式里面加了一个字段，但是旧的写模式里面没有，读取的时候就直接使用默认值。

	   更改模式字段名称和向联合类型添加分支都是向后兼容的，但是不能向前兼容。
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;writer模式是什么&quot;&gt;writer模式是什么？&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;reader如何知道特定的数据采用哪个writer的模式编码的？&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;在每个记录中都包含整个模式不现实因为有时模式甚至比编码数据还要大很多。答案取决于Avro的上下文。例如：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;有很多记录的大文件：所有的记录都用相同的模式进行编码，这种情况下该文件的writer可以仅在文件的开头包含writer的模式信息。&lt;/li&gt;
  &lt;li&gt;具有单独写入记录的数据库：不同的记录可能会在不同的时间点使用不同的writer进行编写，最简单的方法是在每个编码记录的开始处包含一个写模式的版本号，并在数据库里面保留一个模式版本列表。reader可以获取记录，提取版本号，并且从数据库中查询版本号对应的writer模式，使用该writer模式解码记录的其余部分。&lt;/li&gt;
  &lt;li&gt;使用网络连接发送记录：建立通信时协商模式版本，然后在连接的生命周期中使用该模式。这也是Avro RPC协议的基本原理。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在任何情况下，提供一个模式版本信息的数据库都很有用，可以充当一个说明文档来检查系统的兼容性。&lt;/p&gt;

&lt;h3 id=&quot;动态生成的模式&quot;&gt;动态生成的模式&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Avro的一个优点是不包含任何标签号。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;比如一个关系数据库想要把它的内容转储到一个文件中，并且要用二进制格式，可以使用Avro，然后如果数据库模式发生变化（比如加了一列），就可以生成新的Avro模式，用新的模式导出数据即可，每次运行时都可以简单的进行模式转换，由于字段是通过名字来标识的，所以新writer和旧的reader可以匹配。&lt;/p&gt;

&lt;p&gt;相比之下Thrift或者Protocol Buffers需要手动分配字段标签，每次数据库模式更改时都需要手动更新数据库列名到字段标签的映射（虽然可能可以自动化，但是生成器必需十分小心，不能分配以前使用的字段标签）这种动态生成的模式是Avro的目标。&lt;/p&gt;

&lt;h3 id=&quot;代码生成和动态类型语言&quot;&gt;代码生成和动态类型语言&lt;/h3&gt;

&lt;p&gt;Thrift和Protocol Buffers依赖于代码生成，定了模式之后，可以使用静态类型编程语言生成此模式的代码。动态类型编程语言生成代码没太大意义，因为他们避免了明确的编译过程。对于动态生成的模式（比如Avro），代码生成反而是一个障碍。&lt;/p&gt;

&lt;p&gt;Avro为静态类型编程语言提供了可选的代码生成，而且也可以在不生成代码的情况下直接使用。如果有对象容器文件，可以简单地使用Avro库打开它，并用和查看JSON文件一样查看数据。（该文件里面嵌入了writer模式，他是自描述的）&lt;/p&gt;

&lt;h3 id=&quot;模式的优点&quot;&gt;模式的优点&lt;/h3&gt;

&lt;p&gt;尽管JSON、XML和CSV文本数据格式非常普遍，基于模式的二进制编码也有很多不错的属性：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;他们比很多“二进制JSON”变体更紧凑，可以忽略字段名称&lt;/li&gt;
  &lt;li&gt;模式是一种有价值的文档&lt;/li&gt;
  &lt;li&gt;模式数据库允许在部署任何内容之前检查模式更改的向前和向后兼容性&lt;/li&gt;
  &lt;li&gt;对于静态类型编程语言用户来说，从模式生成代码的能力是有限的，它能够在编译时自动检查&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;数据流模式&quot;&gt;数据流模式&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;数据可以通过多种方式从一个进程流向另一个进程。谁编码数据？谁解码数据？&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;基于数据库的数据流&quot;&gt;基于数据库的数据流&lt;/h3&gt;

&lt;p&gt;数据库中的值可能由较新版本的代码写入，然后由仍运行的旧版本代码读取（因为滚动升级中某些实例已经更新，某些实例没有更新）&lt;/p&gt;

&lt;p&gt;数据库当然要支持向后兼容（不然无法读取之前的值了）&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt;：比如记录模式中增加了一个字段，然后用旧的模式去读，更新记录并且写回，理想的行为是旧代码保持新字段不变即使无法解释。&lt;/p&gt;

&lt;p&gt;但是有时比如解释成应用程序中的对象，然后重新编码就有可能丢失未知字段，解决这个问题不难但是要有这个意识。&lt;/p&gt;

&lt;h4 id=&quot;不同时间写入不同的值&quot;&gt;不同时间写入不同的值&lt;/h4&gt;

&lt;p&gt;服务端的应用程序可能会在几分钟内用新版本完全替代旧版本，但是数据库不会这样，五年前的数据仍然采用原始编码，除非已经明确重写了他，这种现象有时被称为&lt;strong&gt;数据比代码更长久&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;将数据重写（迁移）到新模式是可能的，但是代价太大了。&lt;/p&gt;

&lt;p&gt;很多数据库尽可能避免这种操作，关系型数据库允许进行简单的模式更改，例如添加如有默认值为空的新列，而不重写所有数据。读取旧行时数据库会为磁盘上数据缺失的所有列填充为空值。&lt;/p&gt;

&lt;p&gt;因此演化支持整个数据库看起来像是采用单个模式编码，即使底层存储可能包含各个版本模式所编码的记录。&lt;/p&gt;

&lt;h4 id=&quot;归档存储&quot;&gt;归档存储&lt;/h4&gt;

&lt;p&gt;当为数据库备份或者加载到数据仓库时，数据转储通常使用最新的模式进行编码，由于无论何时都要复制数据，所以此时最好对数据副本进行统一的编码。&lt;/p&gt;

&lt;p&gt;由于数据转储是一次性写入的，而且以后不会变，因此像Avro对象容器文件这样的格式非常适合。也可以使用列存储。&lt;/p&gt;

&lt;h3 id=&quot;基于服务的数据流rest和rpc&quot;&gt;基于服务的数据流：REST和RPC&lt;/h3&gt;

&lt;p&gt;网络通信的进程有多种通信方式，最常见的有客户端和服务器。服务器通过网络公开API，客户端可以连接到服务器以向该API发出请求。服务器公开的API称为服务。&lt;/p&gt;

&lt;p&gt;客户端可以向服务器发出网络请求，此外，服务器本身可以是另一项服务的客户端（比如web应用服务器作为数据库的客户端）这种方法通常用于将大型应用程序按照功能区域分解为较小的服务，当一个服务需要另一个服务的某些功能或者数据时，就会向另一个服务发出请求。这种构建应用的方式叫做面向服务的体系结构（ service-oriented-architecture, SOA)，最近更名为微服务体系结构(microservices architecture)&lt;/p&gt;

&lt;p&gt;服务类似于数据库，但是服务公开了特定应用程序的API，他只允许由服务的业务逻辑预定的输入和输出。服务可以对客户端可以做什么不可以做什么施加细粒度的限制。&lt;/p&gt;

&lt;p&gt;微服务的设计目标：通过使服务可以独立部署和演化，让应用程序更加易于更改和维护。&lt;/p&gt;

&lt;p&gt;网络服务：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;运行在客户端的应用程序通过HTTP请求服务。&lt;/li&gt;
  &lt;li&gt;一种服务向同一个组织的另一个服务提出请求（这类软件有时叫做中间件）。&lt;/li&gt;
  &lt;li&gt;一种服务向不同组织的服务提出请求。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;REST：是一个基于HHTP原则的设计理念，它强调简单的数据格式，使用URL来标识资源，并使用HTTP功能进行缓存控制，身份验证和内容类型协商。&lt;/p&gt;

&lt;p&gt;根据REST原则设计的API称为RESTful&lt;/p&gt;

&lt;p&gt;远程过程调用（RPC)的问题&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;本地调用是可预测的，并且成功和失败只取决于参数。网络请求无法预测，请求或响应可能因为网络问题而丢失，或者因为远程计算机可能速度慢或者不可用。&lt;/li&gt;
  &lt;li&gt;本地函数调用要么返回结果要么抛出一个异常，或者永远不会返回，但是网络请求有可能因为超时返回时可能没有结果，不知道请求是否成功。&lt;/li&gt;
  &lt;li&gt;如果重试失败的请求，有可能请求已经完成，只是响应丢失而已，重试的话导致操作被执行多次。&lt;/li&gt;
  &lt;li&gt;每次本地调用所用时间大致相同，远程调用的时间会慢很多，而且也会有很大变化。&lt;/li&gt;
  &lt;li&gt;调用本地函数时可以传指针（高效），但是远程调用只能编码成网络传输的字节序列，当对象比较大时可能会出现问题。&lt;/li&gt;
  &lt;li&gt;客户端可能有不同语言，所以RPC框架必需可以将数据类型从一个语言转化成另一个语言，最终可能会比较丑陋。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;基于消息传递的数据流&quot;&gt;基于消息传递的数据流&lt;/h3&gt;

&lt;p&gt;异步消息传递系统。&lt;/p&gt;

&lt;p&gt;和RPC相比，消息代理（称为消息队列，或面向消息的中间件）的优点：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;如果接收方不可用或过载，可以充当缓存区，从而提高系统的可靠性。&lt;/li&gt;
  &lt;li&gt;可以自动将消息重新发送到崩溃的进程，从而防止消息丢失。&lt;/li&gt;
  &lt;li&gt;避免了发送方需要知道接收方的IP地址和端口号（这在虚拟机和经常启停的云部署中特别有用）&lt;/li&gt;
  &lt;li&gt;它支持将一条消息发送给多个接收方。&lt;/li&gt;
  &lt;li&gt;它在逻辑上将发送方和接收方分离（发送方只是发布消息，并不关心谁使用他们）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;然而和RPC相比，消息队列通常是单向的。发送方通常不期望响应，哪怕有响应也是在一个独立的通道完成。这种通信模式是异步的，只是发送然后忘记它。&lt;/p&gt;

&lt;p&gt;消息代理的使用方式如下：一个进程向指定的队列或者主题发布消息，代理保证消息被传递给队列或主题的一个或多个消费者或订阅者，在同一个主题上可以有多个生产者和消费者。&lt;/p&gt;

&lt;p&gt;主题只提供单向数据流，但是消费者本身可能会将消息发布到另一个主题，也可以发送到一个回复队列，该队列由初始消息发送者来消费。&lt;/p&gt;

&lt;h4 id=&quot;actor框架&quot;&gt;Actor框架&lt;/h4&gt;

&lt;p&gt;Actor模型是用于单个进程中并发的编程模型。逻辑被封装在Actor中，而不是直接处理线程（以及竞争条件，锁定和死锁的相关问题）每个Actor通常代表一个客户端或者实体，可能具有某些本地状态，通过发送和接收异步消息与其他Actor通信。不保证消息传送，在某些情况下，消息会丢失。由于每个Actor一次只处理一个消息，因此不用担心线程，每个Actor都可以由框架独立调度。&lt;/p&gt;

&lt;p&gt;分布式Actor框架，这个模型被用来跨越多个节点扩展应用程序。&lt;/p&gt;</content><author><name>Jeremy Yang</name></author><category term="DDIA" /><summary type="html">数据编码与演化</summary></entry><entry><title type="html">存储与检索</title><link href="http://localhost:4000/%E5%AD%98%E5%82%A8%E4%B8%8E%E6%A3%80%E7%B4%A2.html" rel="alternate" type="text/html" title="存储与检索" /><published>2021-10-24T00:00:00+08:00</published><updated>2021-10-24T00:00:00+08:00</updated><id>http://localhost:4000/%E5%AD%98%E5%82%A8%E4%B8%8E%E6%A3%80%E7%B4%A2</id><content type="html" xml:base="http://localhost:4000/%E5%AD%98%E5%82%A8%E4%B8%8E%E6%A3%80%E7%B4%A2.html">&lt;h2 id=&quot;toc&quot;&gt;TOC&lt;/h2&gt;

&lt;p&gt;一个数据库在最基础的层次上需要完成两件事情：当你把数据交给数据库时，它应当把数据存储起来；而后当你向数据库要数据时，它应当把数据返回给你。&lt;/p&gt;

&lt;h2 id=&quot;驱动数据库的数据结构&quot;&gt;驱动数据库的数据结构&lt;/h2&gt;

&lt;h3 id=&quot;最简单的数据库&quot;&gt;最简单的数据库&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;#!/bin/bash
db_set () {
echo &quot;$1,$2&quot; &amp;gt;&amp;gt; database
}
db_get () {
grep &quot;^$1,&quot; database | sed -e &quot;s/^$1,//&quot; | tail -n 1
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;使用的时候&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ db_set 123456 '{&quot;name&quot;:&quot;London&quot;,&quot;attractions&quot;:[&quot;Big Ben&quot;,&quot;London Eye&quot;]}' 

$ db_set 42 '{&quot;name&quot;:&quot;San Francisco&quot;,&quot;attractions&quot;:[&quot;Golden Gate Bridge&quot;]}'

$ db_get 42
{&quot;name&quot;:&quot;San Francisco&quot;,&quot;attractions&quot;:[&quot;Golden Gate Bridge&quot;]}

$ db_set 42 '{&quot;name&quot;:&quot;San Francisco&quot;,&quot;attractions&quot;:[&quot;Exploratorium&quot;]}'

$ db_get 42{&quot;name&quot;:&quot;San Francisco&quot;,&quot;attractions&quot;:[&quot;Exploratorium&quot;]}

$ cat database
123456,{&quot;name&quot;:&quot;London&quot;,&quot;attractions&quot;:[&quot;Big Ben&quot;,&quot;London Eye&quot;]}
42,{&quot;name&quot;:&quot;San Francisco&quot;,&quot;attractions&quot;:[&quot;Golden Gate Bridge&quot;]}
42,{&quot;name&quot;:&quot;San Francisco&quot;,&quot;attractions&quot;:[&quot;Exploratorium&quot;]}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;底层的存储：一个文本文件，每行包含一条逗号分隔的键值对，每次调用set函数就会追加记录，旧的记录不会被覆盖，所以查找最新值时候，需要找文件中键最后出现的位置。&lt;/p&gt;

&lt;p&gt;优点：在极其简单的场景有很好的性能，因为在文件尾部追加写入很高效。
缺点：当数据库中有大量记录时，查找性能会很差，因为要从头到尾扫描。查找的开销是O(n)。&lt;/p&gt;

&lt;p&gt;所以我们需要&lt;strong&gt;索引&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;索引是附加结构，只影响查询性能，维护额外的结构会产生开销，特别在写入时，因为追加是最简单的写入操作。任何类型的索引通常都会减慢写入速度，因为每次写入数据都需要更新索引。&lt;/p&gt;

&lt;p&gt;所以这里是一个trade off，数据库不会默认索引所有内容，需要DBA通过查询模式来手动选择索引，从而达到最大收益又不会引入超出必要的开销。&lt;/p&gt;

&lt;h3 id=&quot;哈希索引&quot;&gt;哈希索引&lt;/h3&gt;

&lt;p&gt;之前在各种编程语言中已经接触过哈希映射。&lt;em&gt;既然我们已经有内存中数据结构hashmap，为什么不使用它来索引在磁盘上的数据呢？&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;假设我们的数据存储只是一个追加写入的文件，最简单的想法就是在内存中保存一个hashmap，每个键值映射到数据文件中的字节偏移量。（所有键必须能放入到可用内存中）&lt;/p&gt;

&lt;p&gt;像这种方式适合每个键经常更新的情况。例如key可能是视频的url，value是它播放的次数（每次有人点击播放按钮时递增）。这种工作负载中，有很多写操作，但是没有太多不同的键，也就是说每个键都有很多写操作，并且将所有键保存在内存中是可行的。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;追加写入文件如何避免用完磁盘空间呢？&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;将日志分为特定大小的段，当日志增长到特定尺寸时关闭当前段文件，开始写入一个新的段文件，然后对这些段进行压缩（compaction）。压缩是在日志中丢弃重复的键，保留键的最近更新。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jeremy0953.github.io/pics/2021-10-24-pic1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以同时进行压缩和分段合并，在进行过程中我们可以依旧用旧的段来正常提供读写操作。合并完成后，我们开始使用新的合并段然后可以删除掉旧的段文件。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jeremy0953.github.io/pics/2021-10-24-pic2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;真正投入实际应用时需要面临的一些问题：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;文件格式，使用二进制格式会更快更简单（需要以字节单位对字符串进行编码）&lt;/li&gt;
  &lt;li&gt;删除记录，需要在文件中添加一个删除记录，在合并时放弃删除键的任何以前的值&lt;/li&gt;
  &lt;li&gt;崩溃恢复，如果数据库重新启动，内存散列映射会丢失，原则上可以重新从头到尾读取整个段文件然后进行恢复，如果段文件很大就不太好，Bitcask通过存储加速恢复磁盘上每个段的哈希映射的快照，可以更快地加载到内存中。&lt;/li&gt;
  &lt;li&gt;部分写入记录，数据库随时可能崩溃，包括记录附加到日志中途。Bitcask文件包含校验和，可以检测日志中的损坏部分。&lt;/li&gt;
  &lt;li&gt;并发控制，由于写是append模式，所以一般只有一个写入器线程，数据文件段是追加且不可变的所以可以被多个线程同时读取。为什么要用append追加而不是像文件一样覆盖呢？
    &lt;ul&gt;
      &lt;li&gt;追加和分段合并是顺序写入，比随机写入块，尤其是在磁盘上&lt;/li&gt;
      &lt;li&gt;如果段文件是附加或不可变的，并发和崩溃恢复就会很简单，不必担心覆盖值时发生崩溃从而出现既有新值又有旧值。&lt;/li&gt;
      &lt;li&gt;合并旧段可以避免数据文件随着时间推移而分散的问题&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;哈希表的局限性：
    &lt;ul&gt;
      &lt;li&gt;散列表必须能全部放进内存，原则上其实可以在磁盘上保留一个hashmap但是磁盘hashmap由于有很多随机访问I/O所以表现不好。&lt;/li&gt;
      &lt;li&gt;范围查询效率不高。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;sstables和lsm树&quot;&gt;SSTables和LSM树&lt;/h3&gt;

&lt;p&gt;上述日志文件键值对的排序只和写入顺序有关，日志中稍后的值优先于较早的值，除此之外文件中的键值对的顺序并不重要。&lt;/p&gt;

&lt;p&gt;我们做一个小小的变动：要求键值对按照key排序。&lt;/p&gt;

&lt;p&gt;我们称这个格式为&lt;strong&gt;排序字符串表(Sorted String Table)&lt;/strong&gt;，简称SSTable。我们要求每个键只在合并的段文件中出现一次。&lt;/p&gt;

&lt;p&gt;SST的优势：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;合并段简单高效，即使文件大于可用内存。过程就像归并排序中的归并。（如果几个输入段出现了相同的键就只保留最新的）&lt;img src=&quot;https://jeremy0953.github.io/pics/2021-10-24-pic3.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;为了在文件中找到一个特定的key不需要保存所有键的索引，可以知道某个key如果存在就一定在key1和key2之间（其中key1&amp;lt;key&amp;lt;key2）。如果没找到就证明没有这个key。但是仍然需要一些索引告诉某些键的偏移量，不过可以很稀疏了。&lt;img src=&quot;https://jeremy0953.github.io/pics/2021-10-24-pic4.png&quot; alt=&quot;&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;然后就可以将记录分组到块中，对块进行压缩，稀疏索引指向块的开始处。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;磁盘上有序结构有B树之类的，内存中的有序结构有比如红黑树和AVL树，这些数据结构可以任意顺序插入键并且按排序顺序读取他们。&lt;/p&gt;

&lt;p&gt;此时我们的存储引擎工作流程：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;写入时，将其添加到内存中的平衡树数据结构，有时称为内存表(memtable)&lt;/li&gt;
  &lt;li&gt;当内存表大于阈值，将其作为SST写入磁盘（因为已经在内存中排序了所以高效写入）当SST被写入磁盘时，数据库中新的数据写入可以写入到一个新的内存表实例&lt;/li&gt;
  &lt;li&gt;读取请求时先尝试在内存表中找到关键字，然后在最近的磁盘段，或者更久的磁盘段去找。&lt;/li&gt;
  &lt;li&gt;后台运行合并压缩过程的同时丢弃或覆盖旧的值&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这个方案很好，只是会遇到一个问题，当系统崩溃时，最近内存表的写入会丢失，所以我们要在磁盘上保存一个append的日志用来恢复memtable，当memtable被成功写入sst时日志就可以丢弃了。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Log structure merge tree 日志结构合并树(LSM树)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;LSMTree的缺点：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;当查找数据库中不存在的key时，LSM树算法可能会很慢。（因为必须从Memtable一直找到最老的SST才能确定键不存在）为了优化这个访问，存储引擎通常用&lt;strong&gt;布隆过滤器&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;压缩合并的不同策略：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;leveled compaction:关键范围被拆分成更小的SST，旧的数据被移动到单独的水平，使得压缩能都递增进行，减少磁盘空间&lt;/li&gt;
  &lt;li&gt;size-tiered compaction:新的和更小的SST被合并到更老的和更大的SST&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有关LSM这里两种策略的对比可以看&lt;a href=&quot;https://www.alibabacloud.com/blog/an-in-depth-discussion-on-the-lsm-compaction-mechanism_596780&quot;&gt;An In-depth Discussion on the LSM Compaction Mechanism&lt;/a&gt;这篇博客进行进一步了解。&lt;/p&gt;

&lt;p&gt;LSMTree的优点：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;即使数据集比可用内存大仍然能够继续工作&lt;/li&gt;
  &lt;li&gt;由于数据集按照排序存储所以可以高效执行范围查询&lt;/li&gt;
  &lt;li&gt;因为磁盘写入是连续的，所以LSMTree支持非常高的写入吞吐量&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有关LSMTree中的KV分离存储内容可以看迟先生的这篇文章&lt;a href=&quot;https://www.skyzh.dev/posts/articles/2021-08-07-lsm-kv-separation-overview/&quot;&gt;LSM 存储引擎中 KV 分离的实现&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;b树&quot;&gt;B树&lt;/h3&gt;

&lt;p&gt;B树将数据库分解成固定大小的块或者页面，一次只读取或写入一个页面。设计更接近底层硬件，因为磁盘也被安排在固定大小的块中。&lt;/p&gt;

&lt;p&gt;每个页面用地址来标识，允许一个页面引用另一个页面（类似指针）。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jeremy0953.github.io/pics/2021-10-24-pic5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;有关B树的查找，添加，删除，本科数据库课程已经讲得很详细了，比如添加的时候如果页面中没有足够空间就分裂半满页面，删除的时候向兄弟借，(hhh如果想要回顾一下可以翻阅邹老师的PPT)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jeremy0953.github.io/pics/2021-10-24-pic6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;具有n个键的B树总是有O(logn)的深度。大多数数据库可以放入一个三到四层的B树（分支因子为500的4KB页面的四级树可以存储多达256TB）&lt;/p&gt;

&lt;p&gt;B树可靠性：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;为了防止比如页面分裂合并时出现崩溃，会导致一个损坏的索引（可能会有一个孤儿页面不是任何父项的子项），B树通常会有额外的数据结构，预写式日志（WAL，write-ahead-log）当数据库崩溃后用这个恢复一致性。&lt;/li&gt;
  &lt;li&gt;多线程访问，需要锁来保护，但是log-structure的方法在并发控制这里更易于实现，因为后台所有合并不会干扰传入的查询。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;B树优化：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;用写时复制，而不是覆盖页面并且用WAL进行崩溃恢复。修改的页面被写入不同的位置，树中父页面的新版本被创建指向新的位置。&lt;/li&gt;
  &lt;li&gt;不存储整个键，而是可以缩小键的大小。&lt;/li&gt;
  &lt;li&gt;B树尝试布局树，让叶子页面顺序出现在磁盘上。相比之下LSM树在合并时更容易使得顺序键在磁盘上彼此靠近。&lt;/li&gt;
  &lt;li&gt;树中加入额外的指针，每个叶子有对两个兄弟的引用，这样可以直接扫描&lt;/li&gt;
  &lt;li&gt;分形树借用日志结构的思想来减少磁盘寻道。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在数据库的生命周期中写入数据库导致对磁盘的多次写入——被称为&lt;strong&gt;写放大（write amplification）&lt;/strong&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;B Tree&lt;/th&gt;
      &lt;th&gt;LSMTree&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;读取速度更快&lt;/td&gt;
      &lt;td&gt;写入速度更快&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;一段数据写的时候至少写两次，一次写入WAL，一次写入树页面本身，如果分页就更多&lt;/td&gt;
      &lt;td&gt;由于反复压缩合并SST，也会重写数据&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;必须覆盖树中的几个页面，随机写入&lt;/td&gt;
      &lt;td&gt;LSM比B树支持较高的写入吞吐量，部分因为LSM有时具有较低的写放大，部分因为他们顺序写入紧凑的SST文件而不是必须覆盖树中几个页面，磁盘上顺序写入比随机写入快得多&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;由于分割会留下一些未使用的磁盘空间&lt;/td&gt;
      &lt;td&gt;LSM会压缩地更好，由于不是面向页面并且定期重写SST清除碎片，有更低的存储开销，尤其是用leveled compaction&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;B树行为更具可预测性&lt;/td&gt;
      &lt;td&gt;压缩过程有时会干扰读写，磁盘资源有限，很容易发生请求需要等待磁盘完成昂贵的压缩操作，在高百分位点的轻快下，有时响应时间会很长，如果压缩速率跟不上写入速率会导致磁盘空间用完&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;每个键只存在于索引中的一个位置，在OLTP数据库中有优势，且可以直接把锁连接到树&lt;/td&gt;
      &lt;td&gt;LSM会在不同的段中保存某个key的多个副本&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;其他索引&quot;&gt;其他索引&lt;/h3&gt;

&lt;p&gt;二级索引，通常对于有效执行连接至关重要。&lt;/p&gt;

&lt;p&gt;可以在堆文件中存储行的元数据，每个索引引用到堆文件的一个位置。实际的数据保存在一个地方。在不更改键的情况下更新值，堆文件十分高效，只要新value不大于旧value，就可以覆盖记录，如果新value大，可能需要移到堆文件中有足够空间的位置，这猴子那个情况下所有索引都要更新指向新位置，或者在旧堆位置留下一个转发指针。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;聚簇索引：在索引里存放行数据&lt;/li&gt;
  &lt;li&gt;非聚簇索引：仅在索引中存储对数据的引用&lt;/li&gt;
  &lt;li&gt;包含列的索引/覆盖索引：其存储表的一部分在索引内。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;聚簇索引和覆盖索引可以加快读取速度，但是需要额外的存储空间，增加写入开销，需要额外的事务保证。&lt;/p&gt;

&lt;p&gt;多列索引：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;连接索引（concatenated index） 它通过将一列的值追加到另一列后面，简单地将多个字段组合成一个键（索引定义中指定了字段的连接顺序）。比如按照字典序排序的花名册，可以很快查找相同姓氏的人们，或者名字中前几个字相同的人们，但是无法查询最后一个字相同的人们。&lt;/li&gt;
  &lt;li&gt;多维索引（multi-dimensional index）B树和LSM树不支持，可以利用空间填充曲线把二维转换成单个数字再用B树或者直接用R树&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;全文搜索和模糊索引（这些应该是信息检索里面的内容，比如编文档分类辑距离什么的）&lt;/p&gt;

&lt;h3 id=&quot;在内存中存储一切&quot;&gt;在内存中存储一切&lt;/h3&gt;

&lt;p&gt;RAM变得便宜，数据集不那么大，且可以分布在多个机器，内存数据库发展起来了。&lt;/p&gt;

&lt;p&gt;某些内存中的键值存储仅用于缓存，可以接受断电丢失数据，有一些需要达成持久性的，可以用电池供电的RAM将更改日志写入磁盘或者将定时快照写入磁盘来实现。&lt;/p&gt;

&lt;p&gt;内存数据库的性能优势并不是因为它们不需要从磁盘读取的事实（即使是基于磁盘的数据库也可能不需要读磁盘，因为操作系统会在内存中进行缓存），更快的真正原因是省去了将内存数据结构编码为磁盘数据结构的开销。&lt;/p&gt;

&lt;p&gt;Redis由于将所有数据保存在内存中，没所以为各种数据结构（优先级队列和集合）提供了类似数据库的接口，实现起来方便。&lt;/p&gt;

&lt;p&gt;内存数据库也可以支持比内存更大的数据集，比如可以用反缓存(anti-caching)方法将最近最少使用的数据从内存移到磁盘，需要访问的时候再重新加载，有点像OS里面的虚拟内存和交换空间吗，但是数据库可以更有效管理内存，因为可以粒度很小，而不一定是面向页面的。&lt;/p&gt;

&lt;h2 id=&quot;事务处理还是分析&quot;&gt;事务处理还是分析？&lt;/h2&gt;

&lt;p&gt;交互式的应用程序的访问模式称为&lt;strong&gt;在线事务处理（OLTP, OnLine Transaction Processin）&lt;/strong&gt;。查询通常由业务分析师编写，并提供给帮助公司管理层做出更好决策（商业智能）的报告。为了区分这种使用数据库的事务处理模式，它被称为&lt;strong&gt;在线分析处理（OLAP, OnLine Analytice Processing）&lt;/strong&gt;。&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;属性&lt;/th&gt;
      &lt;th&gt;OLTP&lt;/th&gt;
      &lt;th&gt;OLAP&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;主要读取模式&lt;/td&gt;
      &lt;td&gt;查询少量记录，按键读取&lt;/td&gt;
      &lt;td&gt;在大批量记录上聚合&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;主要写入模式&lt;/td&gt;
      &lt;td&gt;随机访问，写入要求低时延&lt;/td&gt;
      &lt;td&gt;批量导入，事件流&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;主要用户&lt;/td&gt;
      &lt;td&gt;终端用户，通过web应用&lt;/td&gt;
      &lt;td&gt;内部数据分析师，决策支持&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;处理的数据&lt;/td&gt;
      &lt;td&gt;数据的最新状态（当前时间点）&lt;/td&gt;
      &lt;td&gt;随时间推移的历史事件&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;数据集尺寸&lt;/td&gt;
      &lt;td&gt;GB~TB&lt;/td&gt;
      &lt;td&gt;TB~PB&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;公司在单独的数据库上进行分析，这个单独的数据库称为数据仓库（data warehouse）&lt;/p&gt;

&lt;h3 id=&quot;数据仓库&quot;&gt;数据仓库&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://jeremy0953.github.io/pics/2021-10-24-pic7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;星型和雪花型分析的模式&quot;&gt;星型和雪花型：分析的模式&lt;/h3&gt;

&lt;p&gt;星型模型：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;模型中心是一个事实表，每一行代表在特定时间发生的时间，然后一些列是属性&lt;/li&gt;
  &lt;li&gt;事实表中其他列是对其他表（维度表）的外键引用，维度代表了时间发生的who,where,what,when,why,how。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://jeremy0953.github.io/pics/2021-10-24-pic8.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中比如尺寸可以进一步分为子尺寸，品牌和产品类型可能有单独的表格，dim表中每一行可能又能将某些列作为外键引用，而不是字符串，这个时候就变成了星型模型。&lt;/p&gt;

&lt;h2 id=&quot;列存储&quot;&gt;列存储&lt;/h2&gt;

&lt;p&gt;事实表中的列数很多，经常超过100列，我们分析查询可能只用到部分列，但是访问大量的行需要将行的全部列都加载，解析他们然后过滤掉不符合要求的条件，很慢很不划算。&lt;/p&gt;

&lt;p&gt;列存储的思想很简单，将来自每一列的所有值存储在一起放在单独的文件，查询只需读取和解析查询中使用的那些列。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jeremy0953.github.io/pics/2021-10-24-pic9.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;面向列的存储还很适合压缩来减少对磁盘吞吐量的需求。&lt;/p&gt;

&lt;p&gt;比如数据仓库中特别有效的一种技术是位图编码。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jeremy0953.github.io/pics/2021-10-24-pic10.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;比如查询&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;WHERE product_sk IN（30，68，69）
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;只需要加载product_sk=30，68，69三个位图并计算位图按位或&lt;/p&gt;

&lt;p&gt;查询&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;WHERE product_sk = 31 AND store_sk = 3 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;只需加载product_sk = 31 和 store_sk = 3 的位图并按位与即可&lt;/p&gt;

&lt;p&gt;一列中不同值的数量与行数相比较小，加入有n个不同值的列，可以转化成n个独立的位图，每个不同值的一个位图，每行一位，如果该行有该值，则该位为1，否则为0。&lt;/p&gt;

&lt;p&gt;如果n很小，则这些位图可以每行存储一位。如果n很大，位图中有很多零，位图可以另外进行游程编码(Run-length encoding)，可以使列的编码十分紧凑。&lt;/p&gt;

&lt;h3 id=&quot;内存带宽和向量处理&quot;&gt;内存带宽和向量处理&lt;/h3&gt;

&lt;p&gt;对于数据仓库查询来说，巨大的瓶颈是从磁盘获取数据到内存的带宽。还有主存储器到CPU缓存中的带宽，避免CPU指令处理流水线中的分支错误预测和泡沫。&lt;/p&gt;

&lt;p&gt;面向列的存储布局也可以有效利用CPU周期。例如查询引擎可以将大量压缩的列数据存放在CPU的L1缓存中，然后在紧密循环中循环（没有函数调用），这样会快很多，而且位图的模式里面的按位与和按位或可以直接运行，这种技术称为矢量化处理。&lt;/p&gt;

&lt;h3 id=&quot;列存储中的排序顺序&quot;&gt;列存储中的排序顺序&lt;/h3&gt;

&lt;p&gt;每个列单独排序是没有意义的，因为那样就不知道列中的哪些项属于同一行。我们重建一行必须要知道一列中的k行和另一列中的k行属于同一行。&lt;/p&gt;

&lt;p&gt;所以要对一整行进行排序。而且还可以有多个排序关键字，可以加快查询速度，同时排序后列存储中相同的值会连续重复多次，有利于压缩。&lt;/p&gt;

&lt;p&gt;第一个排序键的压缩效果最强，第二个和第三个排序键就混乱了，不会有长时间的重复值。&lt;/p&gt;

&lt;h3 id=&quot;写入列存储&quot;&gt;写入列存储&lt;/h3&gt;

&lt;p&gt;利用B树原地更新对于压缩的列是不可能的，因为想要在排序表中插入一行，就不得不重写所有列文件。&lt;/p&gt;

&lt;p&gt;更好的解决方案：LSM树，内存中Memtable是面向行还是列不重要，积累了足够多的写入数据时，将与磁盘上的列文件进行合并，并批量写入新文件。&lt;/p&gt;

&lt;p&gt;查询需要检查磁盘上的列数据和最近在内存中的写入，并将两者结合。查询优化器隐藏了用户这个区别，从分析师角度看，通过插入更新删除操作进行修改的数据会立即反映在后续的查询中。&lt;/p&gt;

&lt;h2 id=&quot;聚合数据立方体和物化视图&quot;&gt;聚合：数据立方体和物化视图&lt;/h2&gt;

&lt;p&gt;由于数据仓库查询总是执行聚集函数，所以可以缓存最频繁的计数。&lt;/p&gt;

&lt;p&gt;创建这种缓存的一种方式是物化视图，物化视图是查询结果的实际副本，当底层数据发生变化时物化视图需要更新，这样的更新成本很高。&lt;/p&gt;

&lt;p&gt;物化视图的特例称为数据立方体或者OLAP立方，是按照不同维度的聚合网络。
&lt;img src=&quot;https://jeremy0953.github.io/pics/2021-10-24-pic11.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面的例子就是对一个轴和另一轴上的产品都进行求和并且存在total里面。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;优点是查询总和时会很快，因为已经预先计算了，还有比如想知道总销售额不用再扫描数万行了。&lt;/li&gt;
  &lt;li&gt;缺点是不具有灵活性，所以数据仓库尽可能保留原始数据，并且将聚合数据仅仅用在某些特定查询上。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;小结&quot;&gt;小结&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;OLTP面向用户&lt;/li&gt;
  &lt;li&gt;OLAP面向数据分析师&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;OLAP方面有两大主流学派的存储引擎&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;log-structure：LSM树什么的，可以实现较高的写入吞吐量&lt;/li&gt;
  &lt;li&gt;update-in-place: B tree&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Jeremy Yang</name></author><category term="DDIA" /><summary type="html">TOC</summary></entry><entry><title type="html">数据模型与查询语言</title><link href="http://localhost:4000/%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80.html" rel="alternate" type="text/html" title="数据模型与查询语言" /><published>2021-10-17T00:00:00+08:00</published><updated>2021-10-17T00:00:00+08:00</updated><id>http://localhost:4000/%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80</id><content type="html" xml:base="http://localhost:4000/%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%9F%A5%E8%AF%A2%E8%AF%AD%E8%A8%80.html">&lt;h2 id=&quot;toc&quot;&gt;TOC&lt;/h2&gt;

&lt;p&gt;对于每层数据模型的关键问题是：&lt;strong&gt;它是如何用低一层数据模型来表示的？&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;一个复杂的应用程序可能会有更多的中间层次，比如基于API的API，不过基本思想仍然是一样的：每个层都通过提供一个明确的数据模型来隐藏更低层次中的复杂性。&lt;/p&gt;

&lt;h2 id=&quot;关系模型与文档模型&quot;&gt;关系模型与文档模型&lt;/h2&gt;

&lt;p&gt;现在最著名的数据模型可能是SQL，他基于Edgar Codd在1970年提出的关系模型：数据被组织成关系（SQL中称作表），其中每个关系是元组（SQL中称作行）的无序集合。&lt;/p&gt;

&lt;h3 id=&quot;nosql的诞生&quot;&gt;NoSQL的诞生&lt;/h3&gt;

&lt;p&gt;NoSQL被解释为（Not Only SQL），NoSQL数据库背后的驱动因素&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;需要比关系型数据库更良好的扩展性，包括更大的数据集和非常高的写入吞吐量&lt;/li&gt;
  &lt;li&gt;免费开源&lt;/li&gt;
  &lt;li&gt;关系模型不能很好地支持一些特殊的查询操作&lt;/li&gt;
  &lt;li&gt;受限于关系模型的限制性，渴望一种更具多动态性于表现力的数据模型&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;不同的应用程序有不同的需求，一个用例的最佳技术选择可能不同于另一个用例的最佳技术选择，因此在可见的未来，关系数据库似乎可能与各种非关系数据库一起使用，这种想法有时被称为&lt;em&gt;混合持久化&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;对象关系不匹配&quot;&gt;对象关系不匹配&lt;/h3&gt;

&lt;p&gt;目前大多数应用开发程序都使用面向对象的语言来开发，如果数据存储在关系表中，则需要一个笨拙的转换层。模型之间的不连贯有时被称为&lt;em&gt;阻抗不匹配&lt;/em&gt;。&lt;/p&gt;

&lt;p&gt;像ActiveRecord和Hibernate这样的&lt;em&gt;对象关系映射（object-relational mapping, ORM）&lt;/em&gt;框架可以减少这个转换层所需的样板代码的数量，但是它们不能完全隐藏这两个模型之间的差异。&lt;/p&gt;

&lt;p&gt;例如一个领英上面的简历的例子：&lt;/p&gt;

&lt;p&gt;如果用关系型数据模型去表征的话：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jeremy0953.github.io/pics/2021-10-17-pic1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;用JSON文档去表示：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
&quot;user_id&quot;: 251,
&quot;first_name&quot;: &quot;Bill&quot;,
&quot;last_name&quot;: &quot;Gates&quot;,
&quot;summary&quot;: &quot;Co-chair of the Bill &amp;amp; Melinda Gates... Active blogger.&quot;,
&quot;region_id&quot;: &quot;us:91&quot;,
&quot;industry_id&quot;: 131,
&quot;photo_url&quot;: &quot;/p/7/000/253/05b/308dd6e.jpg&quot;,
&quot;positions&quot;: [
{
&quot;job_title&quot;: &quot;Co-chair&quot;,
&quot;organization&quot;: &quot;Bill &amp;amp; Melinda Gates Foundation&quot;
},
{
&quot;job_title&quot;: &quot;Co-founder, Chairman&quot;,
&quot;organization&quot;: &quot;Microsoft&quot;
}
],
&quot;education&quot;: [
{
&quot;school_name&quot;: &quot;Harvard University&quot;,
&quot;start&quot;: 1973,
&quot;end&quot;: 1975
},
{
&quot;school_name&quot;: &quot;Lakeside School, Seattle&quot;,
&quot;start&quot;: null,
&quot;end&quot;: null
}
],
&quot;contact_info&quot;: {
&quot;blog&quot;: &quot;http://thegatesnotes.com&quot;,
&quot;twitter&quot;: &quot;http://twitter.com/BillGates&quot;
}
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;JSON表示比关系模型中的多表模式具有更好的局部性，如果在关系型数据库中获取简介信息则需要多表连接，在JSON表示中，所有相关的信息都在一个地方，一个查询就足够了。&lt;/p&gt;

&lt;h3 id=&quot;多对一和多对多的关系&quot;&gt;多对一和多对多的关系&lt;/h3&gt;

&lt;p&gt;解释一下为什么数据库中存的都是ID而不是纯字符串的名字&lt;/p&gt;

&lt;p&gt;如果用户用一个自由文本字段输入区域和行业，那么将他们存储为纯文本字符串是合理的。另一种方式是给出一个区域和行业的列表，让用户从下拉列表中进行选择。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;各个简介之间样式和拼写统一&lt;/li&gt;
  &lt;li&gt;避免歧义&lt;/li&gt;
  &lt;li&gt;易于更新——名称只存在一个地方，如需要修改则很容易进行全面更新。&lt;/li&gt;
  &lt;li&gt;本地化支持——当网站翻译成其他语言时，标准化的列表可以本地化&lt;/li&gt;
  &lt;li&gt;更好的搜索——比如搜索某某地的简历就可以匹配到这个简历（某某地的地名不一定显示出现）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;存储ID还是文本字符串，这是个副本（duplication）问题，当使用ID时，对人类有意义的信息（比如地名）只存储在一处，所有引用它的地方使用ID，当直接存储文本时，对人类有意义的信息就会复制在没处使用记录中。&lt;/p&gt;

&lt;p&gt;使用ID的好处是，ID对人们没有意义，所以也就永远不需要改变。任何对人类有意义的信息都有可能在未来的某个时刻被改变，如果这个信息被复制了多份，所有的副本都需要被更新，这会导致写入开销，也存在不一致的风险（一些副本更新了，一些还没更新）。去除此类重复是数据库规范化（normalization）的关键思想。&lt;/p&gt;

&lt;p&gt;文档模型对于连接的支持很弱。&lt;/p&gt;

&lt;p&gt;一对多的关系：比如简历中一个人的工作经历可能有，公司1，公司2，公司3，这样子是一对多的关系，对于这样的关系模式，文档模型可以很好地去描述。&lt;/p&gt;

&lt;p&gt;多对多的关系：比如简历中的工作经历中的公司1不仅是一个公司的名字而是一个指向公司实体的链接，同理其他的也是，那么这个就是一个多对多的关系，文档模型对于处理这样的多对多的关系比较乏力。&lt;/p&gt;

&lt;p&gt;比如在引用其他公司的时候需要利用到连接操作，但是文档对于连接的支持很弱，或者有些就直接不支持连接，只能在应用程序代码中执行多个查询来模拟连接。&lt;/p&gt;

&lt;h3 id=&quot;文档数据库是否是重蹈覆辙&quot;&gt;文档数据库是否是重蹈覆辙？&lt;/h3&gt;

&lt;p&gt;数据库最开始是一种很简单的数据模型，称为层次模型（hierarchical model），他将所有数据表示为嵌套在记录中的记录树，也是良好地处理一对多的关系但是很难应对多对多的关系，且不支持连接。&lt;/p&gt;

&lt;p&gt;后来人们提出了一些解决方案来解决层次模型的局限性，最突出的两个一个是关系模型，一个是网络模型。&lt;/p&gt;

&lt;h3 id=&quot;网络模型&quot;&gt;网络模型&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;CODASYL模型&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;在层次模型的树结构中，每条记录只有一个父节点，在网络模型中，每个记录可能有多个父节点，网络模型中记录之间的链接不是外键，而更像是编程语言中的指针。访问记录的唯一方法是跟随从根记录起沿这些链路所形成的路径。这被称为访问路径。&lt;/p&gt;

&lt;p&gt;最简单的访问类似与遍历链表一样的访问。但在多对多关系的情况下，可能有不同的路径到达相同的记录，网络模型的程序员必须跟踪这些不同的访问路径。&lt;/p&gt;

&lt;p&gt;网络模型的查询是利用遍历记录列和跟随路径表在数据库中的移动游标来执行的。如果记录有多个父结点，则应用程序代码必须跟踪所有的关系。&lt;/p&gt;

&lt;p&gt;尽管手动选择访问路径能够最有效地利用非常有限的硬件功能，但这使得查询和更新数据库的代码变得复杂不灵活。如果没有路径就会陷入困境，你可以改变访问路径但是要浏览手写大量数据库查询代码。&lt;/p&gt;

&lt;h3 id=&quot;关系模型&quot;&gt;关系模型&lt;/h3&gt;

&lt;p&gt;关系模型是将所有模型放在光天化日之下，一个关系是元组的集合，仅此而已。如果你想读取数据，没有迷宫似的嵌套结构，也没有复杂的访问路径。你可以选中任何符合条件的行，读取特定行或者所有行，或者可以插入新的行。&lt;/p&gt;

&lt;p&gt;关系数据库中，查询优化器会自动决定查询的哪个部分以哪个顺序执行，是自动生成的，不需要由程序员生成。&lt;/p&gt;

&lt;p&gt;如果想要用新的方式查询，可以添加新的索引。&lt;/p&gt;

&lt;h3 id=&quot;关系数据库与文档数据库的对比&quot;&gt;关系数据库与文档数据库的对比&lt;/h3&gt;

&lt;p&gt;多对一的关系（比如许多人生活在一个特性的地区，许多人在一个特定的行业工作）&lt;/p&gt;

&lt;p&gt;在表示多对一和多对多的关系时，关系数据库和文档数据库并没有根本的不同。在这两种情况下，相关项目都被一个唯一的标识符引用，这个标识符在关系模型中被称为外键，在文档模型中被称为文档引用。&lt;/p&gt;

&lt;p&gt;文档数据模型，主要是架构灵活性，因为局部性而拥有更好的性能，对于某些应用程序而言更接近与应用程序所使用的数据结构。关系模型则是为连接提供更好的支以及支持多对一和多对多的关系。&lt;/p&gt;

&lt;h3 id=&quot;哪种更方便写代码&quot;&gt;哪种更方便写代码？&lt;/h3&gt;

&lt;p&gt;如果应用程序中有类似文档的结构，比如一对多关系树，通常一次性加载整个树，那么使用文档模型是一个好主意。&lt;/p&gt;

&lt;p&gt;文档模型有局限性，比如不能直接引用文档中嵌套的项目，而是说“用户251的位置列表中的第二项”。&lt;/p&gt;

&lt;p&gt;如果应用程序不需要多对多关系就没什么问题，但是如果需要多对多的话就不太好了。可以通过规范化减少对连接的需求，也可以在应用程序中模拟连接，等等，但是在这种情况下文档模型会导致更复杂的应用程序代码和更差的性能。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;很难说一般情况哪种数据模型让应用程序代码更简单，取决于数据项时间的关系种类。对于高度相联的数据使用文档模型是糟糕的，但是选用关系模型是可接受的，使用图数据模型是最自然的。&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;文档模型的架构灵活性&quot;&gt;文档模型的架构灵活性&lt;/h3&gt;

&lt;p&gt;大多数文档数据库都不会强制文档中的数据采用何种模式。没有模式意味可以将任意的key和value添加到文档中，当读取的时候，客户端无法保证文档可能包含的字段。&lt;/p&gt;

&lt;p&gt;文档数据库采取读时模式。&lt;/p&gt;

&lt;p&gt;读时模式（schema-on-read）数据的结构是隐含的，只有在数据被读取的时候才被解释。&lt;/p&gt;

&lt;p&gt;写时模式（schema-on-write）传统的关系数据库方法中，模式明确，且数据库确保所有的数据符合其模式。&lt;/p&gt;

&lt;p&gt;当应用程序想要改变数据格式时这两种区别比较大。文档数据库中，只需要开始写入具有新字段的新文档，并在程序中使用代码处理旧文档，例如：&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;if (user &amp;amp;&amp;amp; user.name &amp;amp;&amp;amp; !user.first_name) {
// Documents written before Dec 8, 2013 don't have first_name
user.first_name = user.name.split(&quot; &quot;)[0];
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在写时模式中&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ALTER TABLE users ADD COLUMN first_name text;UPDATE users SET first_name = split_part(name, ' ', 1); -- PostgreSQLUPDATE users SET first_name = substring_index(name, ' ', 1); -- MySQL
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;模式变更的速度很慢并且需要停运。尽管绝大数关系数据库可以在几毫秒内执行ALTER TABLE 语句，但是MySQL是一个例外，他执行ALTER TABLE时会复制整个表，所以更改一个大型表可能会花几分钟甚至几个小时的停机。&lt;/p&gt;

&lt;p&gt;大型表运行UPDATE都会很慢，因为每一行都要改写。&lt;/p&gt;

&lt;p&gt;由于某种原因，集合中的项目并不具有相同的结构时，读时模式更具有优势。比如：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;在许多不同类型的对象，将每种类型的对象放在自己的表中是不现实的。&lt;/li&gt;
  &lt;li&gt;数据的结构由外部系统决定，你无法控制外部系统且它随时可能变化。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在上述情况下，模式的坏处大于好处，无模式文档是一个更加自然的数据模型。要是所有的记录都有相同的结构，那么模式是强制这种结构的有效机制。&lt;/p&gt;

&lt;h3 id=&quot;查询的数据局部性&quot;&gt;查询的数据局部性&lt;/h3&gt;

&lt;p&gt;文档通常以单个连续字符串形式进行存储。如果应用程序经常需要访问整个文档（例如渲染整个网页），那么存储局部性将带来性能优势，如果数据分割到各个表中则需要进行多个索引查找才能全部检索出来，这需要花费更多的时间。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;局部性仅仅适用于同时需要文档绝大部分内容的情况。&lt;/strong&gt;数据库通常需要加载整个文档，如果只是访问很大的文档中的一小部分，这个是很浪费的。而且更新文档的时候需要整个重写，只有不改变文档大小的修改才可以容易地原地执行。所以通常建议保持相对小的文档并且避免增加文档大小的写入。这些性能限制大大减少了文档数据库的实用场景。&lt;/p&gt;

&lt;h3 id=&quot;文档和关系数据库的融合&quot;&gt;文档和关系数据库的融合&lt;/h3&gt;

&lt;p&gt;如果一个数据库能够处理类似文档的数据，并且能够对其执行关系查询，那么应用程序就可以使用最符合其需求的功能组合。&lt;/p&gt;

&lt;p&gt;关系模型和文档模型的混合是未来数据库的一条很好的路线。&lt;/p&gt;

&lt;h2 id=&quot;数据查询语言&quot;&gt;数据查询语言&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;命令式语言&lt;/strong&gt;告诉计算机以特定顺序执行某些操作，比如java语言，循环遍历之类的。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;声明式语言&lt;/strong&gt;如SQL或关系代数，你只需指定所需数据的模式，结果必须符合哪些条件，以及如何将数据转换。但是对于如何实现这个目标并没有要求，数据库的查询优化器去决定使用哪些索引哪些连接方法，以及什么顺序去执行。&lt;/p&gt;

&lt;p&gt;SQL示例不确保任何特定的顺序，因此不在意顺序是否改变。声明式语言往往适合并行执行。（命令代码由于指定了顺序，所以很难在多个机器和多个内核之间并行化，但是声明语言具有并行执行的潜力）&lt;/p&gt;

&lt;h3 id=&quot;web上的声明式查询&quot;&gt;Web上的声明式查询&lt;/h3&gt;

&lt;p&gt;利用CSS选择器要比Javascript的实现方式简洁多了。&lt;/p&gt;

&lt;h3 id=&quot;mapreduce查询&quot;&gt;MapReduce查询&lt;/h3&gt;

&lt;p&gt;MapReduce既不是一个声明式查询也不是一个完全命令式的查询，而是介于两者之间，查询的逻辑用代码片段表示，这些代码片段会被框架重复性调用。它基于map函数和reduce函数，两个函数存在于许多函数式编程语言中。&lt;/p&gt;

&lt;p&gt;map和reduce函数在功能上有所限制，他们必须是纯函数，他们只使用传递给他们的数据作为输入，不能执行额外的数据库查询也不能有任何副作用。这些限制允许数据库以任何顺序执行任何功能并在失败时重新运行他们。然而map和reduce函数仍然是强大的，他们可以解析字符串调用库函数执行计算等等。&lt;/p&gt;

&lt;p&gt;MapReduce是一个相当底层的编程模型，用于计算机集群上的分布式执行。&lt;/p&gt;

&lt;h2 id=&quot;图数据模型&quot;&gt;图数据模型&lt;/h2&gt;

&lt;p&gt;如果多对多的关系在你的数据中很常见，关系模型可以处理多对多关系的简单情况，但是随着数据之间的连接变得复杂，将数据建模成为图形显得更加自然。&lt;/p&gt;

&lt;p&gt;一个图由两种对象组成：顶点和边。&lt;/p&gt;

&lt;p&gt;多种数据可以被建模成为一个图形，比如社交图谱（顶点是人，边指示哪些人彼此认知）网络图谱（顶点是网页，边缘表示指向其他页面的HTML链接）等等。&lt;/p&gt;

&lt;p&gt;有几种不同但是相关的方法来构建和查询图表中的数据，比如属性图模型和三元组存储模型。&lt;/p&gt;

&lt;h3 id=&quot;属性图&quot;&gt;属性图&lt;/h3&gt;

&lt;p&gt;属性图模型中每个结点包括：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;唯一的标识符&lt;/li&gt;
  &lt;li&gt;一组出边&lt;/li&gt;
  &lt;li&gt;一组入边&lt;/li&gt;
  &lt;li&gt;一组属性（键值对）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;每个边包括：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;唯一标识符&lt;/li&gt;
  &lt;li&gt;边的起点/尾部顶点&lt;/li&gt;
  &lt;li&gt;边的终点/头部顶点&lt;/li&gt;
  &lt;li&gt;描述两个顶点之间关系类型的标签&lt;/li&gt;
  &lt;li&gt;一组属性(键值对)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;可以将图存储看做两个关系表组成，一个存储顶点另一个存储边。&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;任何&lt;/strong&gt;顶点都可以有一条边连接到&lt;strong&gt;任何&lt;/strong&gt;其他顶点&lt;/li&gt;
  &lt;li&gt;给定任何顶点，可以高效找到入边和出边，从而遍历图。&lt;/li&gt;
  &lt;li&gt;通过不同类型的关系使用不同的标签，可以在一个图中存储几种不同的信息，同时仍然保持一个清晰的数据模型。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这些特性为数据建模提供了很大的灵活性。以及具有可演化性。&lt;/p&gt;

&lt;p&gt;并且图数据库还有相应的声明式查询语言。查询优化程序会自动选择预测效率最高的策略。&lt;/p&gt;

&lt;p&gt;倒是也可以在SQL中表示图数据并且进行查询，只是很困难很麻烦罢了。&lt;/p&gt;

&lt;h3 id=&quot;三元组存储&quot;&gt;三元组存储&lt;/h3&gt;

&lt;p&gt;三元组存储模式大体上与属性图模型相同，用不同的词来描述相同的想法。&lt;/p&gt;

&lt;p&gt;三元组存储中，所有信息都以三部分表示形式存储（主语，谓语，宾语）比如（吉姆，喜欢，香蕉）&lt;/p&gt;

&lt;p&gt;三元组的主语相当于图中的一个顶点。而宾语是下面两者之一：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;原始数据类型中的值，利用字符串或数字。此时三元组的谓语和宾语相当于主语顶点上的属性的键和值。例如，(lucy,age,33)等价于顶点lucy,并且属性{“age”:33}.&lt;/li&gt;
  &lt;li&gt;图中的另一个顶点。在这种情况下，谓语是图中另一条边，主语是其尾部顶点，宾语是头部顶点。例如，在(lucy,marriedTo,alain)中主语和宾语lucy和alain都是顶点，并且谓语marriedTo是连接他们的边的标签。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;例子：&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@prefix : &amp;lt;urn:example:&amp;gt;.
_:lucy a :Person.
_:lucy :name &quot;Lucy&quot;.
_:lucy :bornIn _:idaho.
_:idaho a :Location.
_:idaho :name &quot;Idaho&quot;.
_:idaho :type &quot;state&quot;.
_:idaho :within _:usa.
_:usa a :Location
_:usa :name &quot;United States&quot;
_:usa :type &quot;country&quot;.
_:usa :within _:namerica.
_:namerica a :Location
_:namerica :name &quot;North America&quot;
_:namerica :type :&quot;continent&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;当谓语表示边时，该宾语是一个顶点。当谓语是一个属性时，该宾语是一个字符串。&lt;/p&gt;

&lt;h3 id=&quot;图数据库与网络模型的比较&quot;&gt;图数据库与网络模型的比较&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;在CODASYL中，数据库有一个模式，用于指定哪种记录类型可以嵌套在其他记录类型中，在图数据库中，不存在这样的限制，任何顶点都可以具有到其他任何顶点的边，这为应用程序适应不断变化的需求提供了更大的灵活性。&lt;/li&gt;
  &lt;li&gt;在CODASYL中，到达特定的记录的唯一方法是遍历一个访问路径，但是图数据库中可以用唯一ID直接引用任何顶点，也可以使用索引来查找具有特定值的顶点。&lt;/li&gt;
  &lt;li&gt;在CODASYL中，记录的后续是一个有序集合，所以数据库的人得维持排序，并且插入新记录的应用程序不得不担心新纪录在集合中的位置，在图形数据库中，顶点和边不是有序的（只能在查询时对结果进行排序）&lt;/li&gt;
  &lt;li&gt;在CODASYL中，所有查询都是命令式的难以编写，并且很容易因为架构中的变化而受到破坏。在图形数据库中，如果需要也可以用命令式代码，但是绝大数图数据库也支持高级声明式查询语言。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;小结&quot;&gt;小结&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;文档数据库的应用场景是：数据通常是自我包含的，而且文档之间的关系非常稀少。&lt;/li&gt;
  &lt;li&gt;图形数据库应用与相反的场景：任意事物都可能与任何事物相关联。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;文档、关系和图形这三种模型在今天都被广泛应用且在&lt;strong&gt;各自的领域&lt;/strong&gt;发挥很好。一个模型也可以用另一个模型来模拟。例如可以用关系数据库模拟图数据，但是结果往往糟糕。这就是为什么我们有着不同目的的不同系统，而不是一个单一的万能解决方案。&lt;/p&gt;

&lt;p&gt;文档数据库和图数据库有一个共同点，通常不会为存储的数据强制一个模式，这可以使得应用程序容易适应不断变化的需求。但是应用程序可能仍然会假定数据具有一定的结构，这只是模式是明确的（写入时强制）还是隐含的（读取时处理）的问题。&lt;/p&gt;</content><author><name>Jeremy Yang</name></author><category term="DDIA" /><summary type="html">TOC</summary></entry><entry><title type="html">可靠性 可扩展性 可维护性</title><link href="http://localhost:4000/%E5%8F%AF%E9%9D%A0%E6%80%A7-%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7-%E5%8F%AF%E7%BB%B4%E6%8A%A4%E6%80%A7.html" rel="alternate" type="text/html" title="可靠性 可扩展性 可维护性" /><published>2021-10-08T00:00:00+08:00</published><updated>2021-10-08T00:00:00+08:00</updated><id>http://localhost:4000/%E5%8F%AF%E9%9D%A0%E6%80%A7-%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7-%E5%8F%AF%E7%BB%B4%E6%8A%A4%E6%80%A7</id><content type="html" xml:base="http://localhost:4000/%E5%8F%AF%E9%9D%A0%E6%80%A7-%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7-%E5%8F%AF%E7%BB%B4%E6%8A%A4%E6%80%A7.html">&lt;h2 id=&quot;toc&quot;&gt;TOC&lt;/h2&gt;

&lt;p&gt;现在很多应用都是数据密集型应用(data-intensive)，而不是计算密集型应用(compute-intensive)&lt;/p&gt;

&lt;p&gt;数据密集型应用的标准组件及其通用功能：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;存储数据（database）&lt;/li&gt;
  &lt;li&gt;加快读取速度(cache)&lt;/li&gt;
  &lt;li&gt;按关键词搜索数据，或对数据进行过滤(search indexes)&lt;/li&gt;
  &lt;li&gt;向其他进程发送消息，进行异步处理(stream processing)&lt;/li&gt;
  &lt;li&gt;定期处理大批量数据(batch processing)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;基础目标：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;可靠性(Reliability)&lt;/li&gt;
  &lt;li&gt;可扩展性(Scalability)&lt;/li&gt;
  &lt;li&gt;可维护性(Maintainability)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;可靠性&quot;&gt;可靠性&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;系统在困境中仍可以正常工作&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;故障(fault)：造成错误的原因,通常定义为系统的一部分状态偏离其标准&lt;/p&gt;

&lt;p&gt;容错(fault-tolerant)：能&lt;strong&gt;预料&lt;/strong&gt;并应对故障的系统特性&lt;/p&gt;

&lt;p&gt;失效(failure): 系统作为一个整体停止向用户提供服务。&lt;/p&gt;

&lt;p&gt;硬件故障的解决方式：增加单个硬件的冗余度、软件容错机制&lt;/p&gt;

&lt;p&gt;软件错误：内部的系统性错误(systematic error)，比如失控进程占用共享资源等，还有比如级联故障等。解决方法：仔细考虑假设和交互，测试，进程隔离，测量监控等等……&lt;/p&gt;

&lt;p&gt;人为错误：运维配置错误是导致服务中断的首要原因。解决方法：以最小化犯错机会的方式设计系统（比如抽象、设计api等等），将人们最容易犯错的地方和可能导致失效的地方解耦(decouple)，提供一个功能齐全的非生产环境沙箱(sandbox)，在各个层次进行彻底的测试，允许从人为错误中简单快速地恢复，配置详细和明确的监控，良好的管理实践与充分的培训。&lt;/p&gt;

&lt;h2 id=&quot;可扩展性&quot;&gt;可扩展性&lt;/h2&gt;

&lt;p&gt;“如果系统以特定方式增长，有什么选项可以应对增长？”&lt;/p&gt;

&lt;p&gt;“如何增加计算资源来处理额外的负载？”&lt;/p&gt;

&lt;h3 id=&quot;描述负载&quot;&gt;描述负载&lt;/h3&gt;

&lt;p&gt;负载参数的最佳选择取决于系统架构，可能是每秒向web服务器发出的请求、数据库中的读写比率、聊天室中同时活跃的用户数量、缓存命中率或其他东西&lt;/p&gt;

&lt;h4 id=&quot;推特的例子&quot;&gt;推特的例子&lt;/h4&gt;

&lt;p&gt;推特发布推文：用户可以向其粉丝发布新消息（平均 4.6k请求/秒，峰值超过 12k请求/秒）。&lt;/p&gt;

&lt;p&gt;主页时间线：用户可以查阅他们关注的人发布的推文（300k请求/秒）。&lt;/p&gt;

&lt;p&gt;处理每秒12,000次写入（发推文的速率峰值）还是很简单的。然而推特的扩展性挑战并不是主要来自推特量，而是来自扇出（fan-out）——每个用户关注了很多人，也被很多人关注。&lt;/p&gt;

&lt;p&gt;有两种实现方式。&lt;/p&gt;

&lt;p&gt;方法1：&lt;/p&gt;

&lt;p&gt;发布推文时，只需要将新推文推入全局推文集合即可，当请求自己的主页时间线时，首先查找他关注的所有人，查询这些被关注用户发布的推文并按时间顺序合并。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jeremy0953.github.io/pics/2021-10-08-pic1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以利用这样子的sql查询&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;SELECT tweets.*, users.*
FROM tweets
JOIN users ON tweets.sender_id = users.id
JOIN follows ON follows.followee_id = users.id
WHERE follows.follower_id = current_user
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;方法2：&lt;/p&gt;

&lt;p&gt;为每个用户的主页时间线维护一个缓存，当用户发布推文时就将新的推文插入到每一个关注者的缓存中。所以读取主页时间线的请求开销很小，因为已经提前计算好了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://jeremy0953.github.io/pics/2021-10-08-pic2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;推特一开始使用方法1，但是系统跟不上查询的负载，所以用了方法2&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;因为发推特的频率比查询主页的频率几乎低了两个数量级，所以这种情况下最好在写入时做更多的工作，在读取时做更少的工作&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;然而方法2的缺点是，发推特需要额外工作，尤其是对于一些粉丝众多的用户，发推特就会有大量的写入工作。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;所以在推特的例子中，每个用户粉丝数的分布（可能按照用户的发推频率来加权）是探讨可扩展性的一个关键负载参数，因为它决定了&lt;strong&gt;扇出负载&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;推特最终的解决方法：两种方法的混合，对于大多数用户采用方法2，对于少量具有海量粉丝的用户使用方法1，当用户读取主页时间线的时候，分别获取关注的明星的推文和自己的主页时间线缓存进行合并。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;妙啊&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;描述性能&quot;&gt;描述性能&lt;/h3&gt;

&lt;p&gt;“当增加负载参数并保持系统资源不变时，系统性能将受到什么影响？”&lt;/p&gt;

&lt;p&gt;“当增加负载参数并希望性能保持不变时，需要增加多少系统资源？”&lt;/p&gt;

&lt;p&gt;对于Hadoop这样的批处理系统，通常关心的是吞吐量(throughput)，即每秒可以处理的记录数量。对于在线系统，更重要的是响应时间(response time)，即客户端发送请求到接受响应之间的时间。&lt;/p&gt;

&lt;p&gt;延迟(lantency):某个请求等待处理的持续时长，在此期间处于休眠状态，并等待服务。&lt;/p&gt;

&lt;p&gt;响应时间(respense time):用户看到的，除了实际处理请求的时间，还包括网络延迟和排队延迟。&lt;/p&gt;

&lt;p&gt;我们需要把响应时间视为一个可以测量的数值分布，而不是单个数值。&lt;/p&gt;

&lt;p&gt;通常报表会展示平均响应时间(但是当你想知道典型响应时间，平均值不好)&lt;/p&gt;

&lt;p&gt;通常使用百分位点(percentiles)会更好，比如中位数就是p50，一半服务时间小于中位数，一半大于中位数，为了弄清楚异常值有多糟糕，可以看更高的百分位点比如p95,p99,p999(以为着95%,99%,99.9%的请求响应时间比该阈值快)&lt;/p&gt;

&lt;p&gt;响应时间的高百分位点（也叫做尾部延迟(tail latencies)）非常重要，因为它们直接影响用户服务体验，比如亚马逊描述内部响应时间用p999，即使只影响1000个中的1个，但是因为请求响应最慢的客户也是数据最多的客户，也可以说是最有价值的用户。&lt;/p&gt;

&lt;p&gt;排队延迟：由于服务器只能并行处理少量的事务(受CPU核数的限制)，所以有少量缓慢的请求就阻碍后续，称为头部阻塞(head-of-line blocking)。&lt;/p&gt;

&lt;p&gt;当负载参数增加时，如何保持良好的性能？&lt;/p&gt;

&lt;p&gt;纵向扩展(scaling up)(垂直扩展(vertical scaling)，转到更强大的机器)和横向扩展(scaling out)(水平扩展(horizontal scaling)，将负载分布到多台小机器上)&lt;/p&gt;

&lt;p&gt;跨多台机器部署无状态服务(stateless services)非常简单，但将带状态的数据系统从单节点变为分布式配置则可能引入许多额外复杂度。&lt;/p&gt;

&lt;p&gt;随着分布式系统的工具和抽象越来越好，可以预见分布式数据系统将成为未来的默认设置。&lt;/p&gt;

&lt;p&gt;大规模的系统架构通常是&lt;strong&gt;应用特定&lt;/strong&gt;的，&lt;strong&gt;没有可以一招鲜吃遍天的通用可扩展架构&lt;/strong&gt;，应用的问题可能是读取量、写入量、要存储的数据量、数据的复杂度、响应时间要求、访问模式或者所有问题的大杂烩。&lt;/p&gt;

&lt;p&gt;举个例子，，用于处理每秒十万个请求（每个大小为1 kB）的系统与用于处理每分钟3个请求（每个大小为2GB）的系统看上去会非常不一样，尽管两个系统有同样的数据吞吐量。&lt;/p&gt;

&lt;p&gt;一个良好适配应用的可扩展架构，是围绕着假设建立的，哪些操作是常见的？哪些操作是罕见的？这就是所谓负载参数。&lt;/p&gt;

&lt;h2 id=&quot;可维护性&quot;&gt;可维护性&lt;/h2&gt;

&lt;p&gt;可维护性又分为&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;可操作性(Operability)&lt;/li&gt;
  &lt;li&gt;简单性(Simplicity)&lt;/li&gt;
  &lt;li&gt;可演化性(evolability)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;可操作性&quot;&gt;可操作性&lt;/h3&gt;

&lt;p&gt;便于运维团队保持系统平稳运行&lt;/p&gt;

&lt;p&gt;比如通过良好的监控，提供对系统内部状态的可视性，提供良好的文档和易于理解的操作模型等等等等&lt;/p&gt;

&lt;h3 id=&quot;简单性管理复杂度&quot;&gt;简单性：管理复杂度&lt;/h3&gt;

&lt;p&gt;复杂度（complexity）有各种可能的症状，例如：状态空间激增、模块间紧密耦合、纠结的依赖关系、不一致的命名和术语、解决性能问题的Hack、需要绕开的特例等等&lt;/p&gt;

&lt;p&gt;消除额外复杂度的最好工具之一是&lt;strong&gt;抽象&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;比如SQL就是一种抽象，隐藏了复杂的磁盘/内存数据结构、来自其他客户端的并发请求、崩溃后的不一致性。&lt;/p&gt;

&lt;h3 id=&quot;可演化性拥抱变化&quot;&gt;可演化性：拥抱变化&lt;/h3&gt;

&lt;p&gt;敏捷工作模式，敏捷技术：如测试驱动开发(TDD,test-driven development)和重构(refactoring)&lt;/p&gt;

&lt;p&gt;修改数据系统并使其适应不断变化需求的容易程度，是与简单性和抽象性密切相关的：简单易懂的系统通常比复杂系统更容易修改。但由于这是一个非常重要的概念，我们将用一个不同的词来指代数据系统层面的敏捷性：可演化性（evolvability）&lt;/p&gt;</content><author><name>Jeremy Yang</name></author><category term="DDIA" /><summary type="html">TOC</summary></entry><entry><title type="html">写在保研之后</title><link href="http://localhost:4000/%E5%86%99%E5%9C%A8%E4%BF%9D%E7%A0%94%E4%B9%8B%E5%90%8E.html" rel="alternate" type="text/html" title="写在保研之后" /><published>2021-10-03T00:00:00+08:00</published><updated>2021-10-03T00:00:00+08:00</updated><id>http://localhost:4000/%E5%86%99%E5%9C%A8%E4%BF%9D%E7%A0%94%E4%B9%8B%E5%90%8E</id><content type="html" xml:base="http://localhost:4000/%E5%86%99%E5%9C%A8%E4%BF%9D%E7%A0%94%E4%B9%8B%E5%90%8E.html">&lt;h3 id=&quot;一次心血来潮的阶段性总结&quot;&gt;一次心血来潮的阶段性总结&lt;/h3&gt;

&lt;p&gt;今天是2021年10月3日，距离保研结束已经过去了好几天，去向也最终尘埃落定了，未来三年半将要继续在哈尔滨进行下一阶段的学习。&lt;/p&gt;

&lt;p&gt;突然发现一晃大学四年的本科生活也已经接近尾声，而我也已然在哈尔滨度过了三个春秋。&lt;/p&gt;

&lt;h3 id=&quot;三年前&quot;&gt;三年前&lt;/h3&gt;

&lt;h4 id=&quot;高中&quot;&gt;高中&lt;/h4&gt;

&lt;p&gt;现在想想高中时候的事已经是很久很久以前了，还记得中考后的我一个很高的成绩（大概是全市五十多名左右的样子）从一所很普通很普通的中学一骑绝尘考入到了全市最好的高中的实验班，那时可能是第一次对自己的能力有了一个大概的预估，大概是第一次觉得自己有可能以后考到一所很不错的985高校。&lt;/p&gt;

&lt;p&gt;那个暑假我很开心，或者可以用意气风发来形容。&lt;/p&gt;

&lt;p&gt;因为有亲戚在南京，加上自己一直对南方都很向往，所以那个暑假特意去了南京待了二十多天，也顺路去了杭州上海。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;印象里南大校园很好看，有法式梧桐，北大楼门口有草坪后面就是紫峰大厦，浙大校园离西湖很近，上交的建筑风格我好喜欢，复旦同济门口就是五角场。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;可能就是那时这几所高校在我的心里埋下了一颗小小的种子，觉得自己可能考不上清北，但是这几所学校还是可以努努力奋斗一下的。&lt;/p&gt;

&lt;p&gt;进入高中期间的学习虽然比起初中压力大了不少，不过好在前两年成绩也比较稳定，只是稳定在班级中游罢了。&lt;/p&gt;

&lt;p&gt;记得高三那年冬天因为压力太大曾经每天特别压抑，状态十分不好而且成绩也出现了较大波动，后来春天开学之后刚哥特意把我调到了讲台下面第0排的位置，也非常感谢最后的那个阶段身边的战友高宝还有王妍的陪伴，后来自己的心态还有状态也都逐渐调整了回来。&lt;/p&gt;

&lt;h4 id=&quot;高考&quot;&gt;高考&lt;/h4&gt;

&lt;blockquote&gt;
  &lt;p&gt;高考的记忆仅剩自己最后也没敢写在作文里的“幸存者偏差”，理综考场上半个小时没做出来的电磁场大题，和648分压线进工大计算机的高考成绩。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;记得当初高考前出分之前的忐忑紧张，以及看到648出现在眼前时，心里对于没有发挥好的一点点失落，以及好在没有考砸了的欣慰，嘴上说着，“嗯这个成绩正常发挥嘛，应该能去武大了”。&lt;/p&gt;

&lt;p&gt;但我知道当时自己心里对于这个成绩是不满意的。&lt;/p&gt;

&lt;p&gt;6月23号那天看到一个个春风满面的认识的或是不认识的同学，我一直有点不舒服，我不知道是什么情绪，可能是羡慕，也可能是眼红，也可能是对自己的懊悔，也可能是对于环境的埋怨，我不知道。&lt;/p&gt;

&lt;p&gt;好在那时已经明确了自己一定要学计算机，不光是看到就业前景，更主要的是高中备考期间看了很多比如陆奇、雷军的成长历程，觉得对比起其他传统工科，计算机这门学科学的都是最新的技术，而且这项技术也在真真切切让人们的生活产生了翻天覆地的变化，如果我能有机会成为无数工程师的一员，为某个项目添砖加瓦，自己也在为改变世界做出一点点力。&lt;/p&gt;

&lt;p&gt;唯一的一个好消息可能是那天发现自己的成绩刚好可以压线进工大计算机。&lt;/p&gt;

&lt;p&gt;还记得那个假期启程去哈尔滨前，爸爸在饭桌上语重心长地和我讲大学一定要好好学习，争取保研保出来，或者也可以继续留在那里深造工作的时候再出来。&lt;/p&gt;

&lt;p&gt;原本心心念念想去南方上大学，最后阴差阳错地来到了祖国的最北方。&lt;/p&gt;

&lt;h3 id=&quot;大一&quot;&gt;大一&lt;/h3&gt;

&lt;p&gt;刚上大学懵懵懂懂，发现自己对于计算机的了解为0，然而身边已经有很多早就打了很多年OI竞赛的同学，自己想要努力弥补自己的不足，只能成天抱着一本C语言教材啃，结果忽视了微积分和线代，一场期中考试就被狠狠地教育了一通，为了不挂科后面就转而闷头学数学，想着万一以后考研这些都是考研要考的，好好学准没问题。嗯对，当时就没怎么想过太多保研的事情，觉得万一保不上就考研考出去。&lt;/p&gt;

&lt;p&gt;结果后来期末数学成绩争气了一把都考到了90+，然后C语言也考到了90+，好像两者都考得还不错，也好像总成绩排名似乎也还凑乎，似乎如果继续保持后续还有希望保研。&lt;/p&gt;

&lt;p&gt;当时突然觉得如果能顺便能将绩点也考高的话可能能多一条路，也不是不可以。然后就阴差阳错地加入了卷学分绩争保研的队伍中来了。&lt;/p&gt;

&lt;h3 id=&quot;大二&quot;&gt;大二&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;大二那年是我最开心的一年。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;那年从二校区搬到了一校区，新组了6人寝室，舍友们都很有趣，虽然白天可能各自都不在寝室晚上十点多都陆续回了寝室大家一起开心地唠嗑。&lt;/p&gt;

&lt;p&gt;那年学校开了数据结构、计算机系统这些很难又很重要的计算机基础课程，记得当时学得很吃力，尤其是计算机系统那一门课和《CSAPP》那一本很厚很难啃的教材，每天听着老师飞速念着根本听不大懂的PPT，周末在寝室借着一盏微弱的灯光去一点点地读那本教材，然后一点点去扣那些当时看来很难很难的课程实验，每周仅仅依靠着约定周五周六晚上学习完玩一两个小时来调剂一下。&lt;/p&gt;

&lt;p&gt;整个过程虽然辛苦，但很快乐，当后来期末复习，自己学到多级页表时，学到多级存储换入换出时，我现在仍然记得19年的圣诞节，自己一个人在空荡荡的教室里将CSAPP那本书的某些知识前后连通起来的那一瞬间，突然觉得计算机系统设计特别精妙，那天晚上，路上零下二三十度的低温，除了三三两两过节的同学们，还有一个一脸傻笑着小跑回寝室的男孩子。&lt;/p&gt;

&lt;p&gt;当然最后一整年的成绩也都不错，那时自己也意识到了大二结束之后，读研就业出国便已经成为了三条不怎么相交的路线，也在那时觉得自己还是要走保研这条路，就业的事情等硕士再做打算。&lt;/p&gt;

&lt;p&gt;如今再去想想为什么大二的时候最开心，可能是因为大二不像大一那样懵懂，而是已经了解了一些大学中学习规律和特点，从而能更好地分配自己的精力，大二也不像大三那样突然感觉自己来到了人生的十字路口，突然一下子就要去考虑未来升学、就业等等的一系列未知的事情，去不断衡量每一种选择的利与弊，去不停地考量自己究竟适合哪一条路。大二那年的我心里只有那几门很难但是很有意思的专业课，那几位讲课很棒很棒的老师，那个不算特别高也一点都不低的绩点，每天晚上回宿舍后那几位很合得来的舍友，每周末结束一天的学习后从教学楼小跑回来彻底放松的的那些晚上。&lt;/p&gt;

&lt;h3 id=&quot;2021&quot;&gt;2021&lt;/h3&gt;

&lt;blockquote&gt;
  &lt;p&gt;2021的关键词是焦虑与迷茫&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;2021年的开始便是灰色的，还记得大三刚开始使信心满满地选择了学校里面最难也是最卷的自然语言处理方向，结果经历了半年的摧残，让我成功地对nlp还有深度学习从好奇到乏味甚至到排斥，最终这门课也给了我一个刚上80的成绩对我的态度还以颜色。&lt;/p&gt;

&lt;p&gt;印象中那个寒假很冷很漫长。&lt;/p&gt;

&lt;p&gt;那个寒假应该是自己第一次确定一定一定要争取保研，并且保证万无一失。&lt;/p&gt;

&lt;p&gt;保本校还是外校？继续做NLP方向还是换方向？换方向是该换什么方向？以后是做科研还是去企业？去做算法还是开发？研究生是否要选一个自己感兴趣的方向？以后工作能否找到对口的岗位的工作？&lt;/p&gt;

&lt;p&gt;那个寒假里这些问题也一直萦绕在我的心头。&lt;/p&gt;

&lt;p&gt;那也是我第一次尝试去了解学校里各个实验室的研究方向、去了解互联网公司岗位招聘情况以及学长学姐们的就业的情况。&lt;/p&gt;

&lt;hr data-content=&quot;要不要继续做自然语言处理方向？&quot; /&gt;

&lt;p&gt;首先第一个问题，要不要继续做nlp方向的研究？一来自己实在是对机器学习还有深度学习那一套并不感兴趣，还有大三上半年的学习让我感觉自己并不适合继续做机器学习之类的东西，首先情感上我自己就有点排斥这种类似黑箱一样的技术，炼丹一样的训练过程，我更喜欢传统的CS的技术，比如像计算机系统中的各种优美精巧的算法，整个算法流程的每一步都是可以追溯的，而不是像自己去训练简单的机器学习模型并不知道内部拟合过程而且也无法对实验结果达不到预期做出解释。其次，我想一个真正有竞争力的机器学习工程师应该可以了解各个模型的优缺点，并且能够对每一组数据在特定模型下的不同表现做出合理解释，但是这个需要强大的数学功底，可惜我自己做不到。虽然我机器学习课程考了教学班第一97分，但是我自己知道考得好和学得好是两件交集并不算很大的事情，也知道自己的水平并不足以支撑自己继续进行这方面的研究。&lt;/p&gt;

&lt;p&gt;同时也去了解了关于AI方向求职的信息，才发现之前大家一窝蜂涌入的AI方向也并不像之前媒体渲染的那么强大，也并不是很多人的乌托邦，很多公司的AI算法岗位变得很难进，手握顶会文章可能才是入场券，早已不是很多年前有一些相关经验就可以轻松找到高薪工作的年代了。不过哪怕是现在我依旧认为AI是未来，我也认为这个领域依旧需要很厉害很厉害的人让AI更新迭代，我有幸身边有一些这样子很厉害很厉害的同学，不过我认为那里面并没有我的位置。&lt;/p&gt;

&lt;p&gt;OK，那基本上决定了自己应该是去公司里面去做研发的岗位，我也觉得研发的岗位相对于机器学习或者深度学习算法的岗位要更多，并且研发和算法一样也都是不可或缺的。&lt;/p&gt;

&lt;p&gt;NLP再见，这应该是2021年做的第一个重大决定。&lt;/p&gt;

&lt;hr data-content=&quot;那么保研去什么实验室？&quot; /&gt;

&lt;p&gt;那么下一步保研要去哪里呢？于是便开始厚着脸皮去通过各种方式加上本校研究生学长学姐去依次了解各个实验室的情况。才发现校园里面可能有七八成的实验室都在做AI相关的研究，不管是相关或者不相关的方向现在都和AI相关了。可是这些学生毕业之后都会从事AI相关的工作吗？实验室里面的这些项目能落地吗？什么都要扯上AI是为了好发文章教授可以评职称学生可以毕业吗？我们社会上真的需要这么多做AI的人才吗？或者是像我这样子只会瞎调调参数根本不知道为啥出了结果的废柴真的可以吗？&lt;/p&gt;

&lt;p&gt;后来和几个研究生学长去聊才发现一个普通平凡的工大计算机研究生的路线大概是学校里找一个不上不下的实验室，研一一年要有很多很多课去上，实验室或宽松或紧都不会放实习，大家去实验室的热情也不是很高，由于学制只有两年，研二一开学就面临着秋招找工作，所以大家都会早早地就开始做找工作的准备，然后研二直接秋招找工作，研二下去做一个毕业设计就可以直接毕业入职了。这和我想象中的研究生生活很不一样。&lt;/p&gt;

&lt;p&gt;那我要不要也一样随波逐流找一个nlp实验室然后一边应付课题一边把主要精力投入到自己刷题准备面试找工作上？不，我不想这样。如果能尽可能让研究生的研究方向和未来的就业方向对口就再好不过了。可是如果未来想去做研发的话，这么多搞AI相关的实验室哪个是对口的呢？哪个实验室的研究和未来的工作能够大部分相关呢？&lt;/p&gt;

&lt;hr data-content=&quot;要不要转到软件工程？&quot; /&gt;

&lt;p&gt;一次偶然的巧合之下，突发奇想要不要研究生从计科转到一个软工的实验室，感觉软工那边的实验室可能相对于计科这边的实验室会多一些工程类的项目去做，对于之后找研发类型的工作可能会比较有帮助，于是便想到去学校里面曾将教过我软件构造的王忠杰老师（准确地讲是自己去蹭过课）那里读研，也厚着脸皮加了一些学长学姐，然后感觉老师那里可能比较严格比较push，但是心里想着如果和之后的就业方向一致的话push一些也没什么不好的，吧？&lt;/p&gt;

&lt;p&gt;再后来就是春天开学后直接去找了老师去面谈，老师也非常爽快地想让我加入他的项目组，然后还推了一个学长来带我，那个学长是做微服务方向的，然后也给我推荐了一本书还有安排了一些小任务，老师想让我在春季学期尽快学会这些技术然后一到暑假就开始项目实战。&lt;/p&gt;

&lt;p&gt;当然那个学期一直忙于找实习、做课设、刷绩点，所以就咕咕咕了……&lt;/p&gt;

&lt;hr data-content=&quot;备受打击的春季学期&quot; /&gt;

&lt;p&gt;由于秋季学期考试失利，所以对于保研来说，当时的绩点可能没有那么稳(可能是我自己太过谨慎，事实证明我被打脸，后来今年保研名额增加，然后通过竞赛超过我的同学也没有想象中那么多，最后还是毫无悬念地保研了)所以不得不在大三下依旧去刷学分绩，数据库系统、信息检索这三门课一门比一门硬核，除了数据库系统，其他两门课课上讲得东西根本听不懂并且提不起兴趣，实验也是又多又难，不过好在最后还是熬过来了（尽管做了很大努力最后这学期依旧还是掉分了……）&lt;/p&gt;

&lt;p&gt;互联网上信息的渲染让我第一次意识到了实习可能很重要，而工大由于地理位置因素还有研究生学制的因素，并不能像想象中那样子研究生就可以出去实习找工作，一个学长和我说找实习最佳的时间就是大三结束的时候，于是乎自己就在大三下的时候也去赶忙投了一些简历，阿里，字节，携程，想着尽可能在研究生之前就积攒一些实习经验补足这一块。&lt;/p&gt;

&lt;p&gt;可是一边忙着学校里的课程，一边才开始匆匆准备实习的笔试面试让我一下子倍感压力，也让我头一次感受到了求职的艰辛。&lt;/p&gt;

&lt;p&gt;由于准备匆忙加上自己基础不牢，面试的结果可想而知，我现在依然记得自己去面试字节的时候感觉自己就像是去搞笑的，问自己的计网项目稍微一深挖就不知道回答什么了，然后好不容易问到了一个我准备过的面试题“java里面的hashmap具体是怎么实现的？”“由链表和红黑树构成，当数据量大于8的时候自动由链表变成红黑树”心里想着终于能答上来一道，后面那个面试官“你来解释解释为什么用红黑树不用AVL树？”我“不知道……可能是查询更快吧”（然而当时我心里其实根本早就忘记了AVL树是什么），最后面试官很无奈说那我们做一道算法题吧，然后自己憋了半天最后写出了一个跑不出正确结果的代码，面试官和我面面相觑，最后我只能抱歉地说浪费了您的时间。&lt;/p&gt;

&lt;p&gt;那时突然想到了之前另一个学长和我说的一句话“那些能找到实习的同学哪怕不实习也能秋招找到工作”&lt;/p&gt;

&lt;p&gt;再加上自己之前也咨询过一个研二学姐，那个学姐虽然也去了微软亚洲研究院实习，但是由于那里并不能转正，然后再找其他其他公司时候面试去问实习也是去问项目细节去看实习的含金量，所以就算是实验室的项目或者是实习的项目都是可以的，只要是真正有东西的项目企业不会不重视的。&lt;/p&gt;

&lt;p&gt;而且也听说了很多实习做着杂活并没有转正结果浪费了暑假宝贵的准备秋招的时间的例子。&lt;/p&gt;

&lt;p&gt;所以思想观念也从一开始的必须实习变成了后面辩证性地看待实习这件事情。&lt;/p&gt;

&lt;p&gt;说起找实习经历，让我最感谢的是阿里巴巴国际站一面时候遇到的一个面试官大哥。&lt;/p&gt;

&lt;p&gt;那天和那个面试官聊了好久好久，面试官也没有用刁钻的面试题来为难我，更多的是去问我项目中的思想还有自己的想法，后来在最后向面试官提问的环节我向他寻求一些对于在校期间技术方面的建议，很令我惊讶的是，这位面试官并没有像网上那些贩卖焦虑的营销号或者是刚刚入职的学长学姐一样说多刷算法题，多刷面经或者是多找实习，而是推心置腹地和我说，他在互联网行业这么多年（电话面试听声音感觉前辈已经三四十岁了）感觉在校期间最重要的还是比如数据结构、操作系统、计算机网络这些最最基础的三板斧，不管是哪一波浪潮来了，不管是最一开始PC上面的互联网，还是后面移动端或者是现在的AI浪潮，最底层的那些东西都是不变的，所以在学校里面打下牢固的基础才是最最重要的，然后他说他面试校招生的时候感觉学生会有一个误区，就是比如去问计算机网络的时候倒是很多很多问题都能对答如流，问操作系统的时候也是可以对答如流，但是很多问题都是割裂的没有一个成体系的感觉，当在这个行业待久了就会知道这些计算机底层的知识其实是可以融会贯通的，当你能将这些知识融会贯通起来的时候就是你真正有了扎实的计算机基础的时候。&lt;/p&gt;

&lt;p&gt;真的真的很感谢很感谢那位愿意陪我电话面试唠一两个小时嗑的阿里面试官。&lt;/p&gt;

&lt;p&gt;经过开学一个多月的彷徨，也咨询了形形色色的人，发现了一个有趣的现象，当去问正在找工作或者刚入职的学长学姐，他们会说一定一定要多找实习或者多刷题多背面经，问企业里比较资深的工程师的时候，他们会说一定要在学校里面打好扎实的计算机基础，问学校里面的教授或者导师，他们会说研究生阶段最重要的培养自己的研究能力，而这项能力也是以后工作中所必须具备的。&lt;/p&gt;

&lt;p&gt;我想，可能是因为每个人的观点都是基于自身视角所给出的，每个人所经历的事情每个人所在的立场不一样自然会给出不同的结论。&lt;/p&gt;

&lt;p&gt;但我逐渐认识到，学校的title大不大并没有想象中那么重要，学历只是敲门砖罢了，工大的title足以叩开绝大多数互联网公司的绝大多数部门的大门了，后面表现如何，就真的真的只看自己的个人能力了。&lt;/p&gt;

&lt;p&gt;而就是那些面试让我深刻意识到自己的能力是有多差，正如好友汪泽昊后来和我说的“不少工大计院的同学从一入学就开始做梦，直到某一瞬间梦醒了，可能是保研前，也可能是找实习的时候，也可能永远没醒过来，对于我来说是在今年保研前”，我想对于我自己来说，可能是春天找实习的时候，梦突然醒了，让自己真正意识到自己最应该做的是提升自己的能力，将自己之前的坑都补全，而不是为自己能够保研而沾沾自喜。&lt;/p&gt;

&lt;p&gt;这几年也有幸见过一些学校里真正厉害的大佬们，有的本科就早早进实验室开始做科研发出顶会文章，有的在各种竞赛中斩获国家级奖项，有的自己凭着兴趣去自己做很多小项目，有的绩点遥遥领先每年国奖拿到手软保送top2或华五，才慢慢意识到同一个学校里面同学和同学之间的差距远远大于学校与学校之间的差距，而自己只是一个代码能力差的一比勉勉强强将绩点刷高捞了个保研的混子罢了。&lt;/p&gt;

&lt;p&gt;不过哪怕是最终终于卷出来了，对于学校的培养方案课程设置还有评分机制还是有很多很多要吐槽的地方，自己虽然在大二的时候就已经意识到了自己既然选择绩点优先的路的时候就要承受现在这样的结果（当时想着等到保研一结束的大四还有研究生阶段就要以能力为优先导向去学习，现在看来好在自己的去向也基本符合自己的预期），但还是在前三年的学习历程中做了很多妥协，为了绩点做了很多我认为没有太多意义的事情，比如一个简简单单的实验报告为了写的好看专门去学latex，然后花一两天时间专门去写报告去排版（对就是之前我diss的那门机器学习课程，当然最后成绩确实是很好看），这些做法其实一直在我心里是嗤之以鼻的，但是为了绩点确确实实自己在大二大三这两年去将时间花在了这些事情上了。&lt;/p&gt;

&lt;p&gt;作为一个绩点制度和以保研为导向的单一评价体系下的既得利益者反过来去说这个制度的种种不好，未免也挺滑稽的。&lt;/p&gt;

&lt;p&gt;好在自己梦醒了，也有自知之明，也即将开启新的以提升自身能力为导向的阶段。&lt;/p&gt;

&lt;p&gt;于是此时再去看保研保到什么地方，我便不像之前那样唯title论，而是觉得最适合自己的才是最好的。&lt;/p&gt;

&lt;hr data-content=&quot;似乎有机会圆梦南大&quot; /&gt;

&lt;p&gt;依旧还是大三下那个学期，有一次浏览南京大学软件学院的网站的时候，看到里面的实验室还有老师的简介，找到了一个研究方向和未来工作十分贴合的老师，基本上都是工程开发的项目，比如什么基于微服务的应用开发，部署及维护，熟练掌握docker，消息队列等技术……当看到这个的时候一下子就心动了，这不就是和以后后台开发之类的工作十分吻合的项目吗？而且了解到南软专硕只有两年而且必须去企业实习，我一下子就觉得如果为了硕士毕业就直接就业的话这个简直是完美的选择。&lt;/p&gt;

&lt;p&gt;后来联系到了老师，而且非常幸运的是老师对于我也十分认可，在4月份就参加了一次对方实验室的面试，并且面试结果也还不错，所以从整个4月到7月都是一边努力准备期末考试保证能拿到保研资格，一边等着这边期末考试结束之后着手准备南软的夏令营，心里觉得这肯定是稳了，而且终于终于有机会圆梦南大，所以一直一直心里都很欣喜激动。&lt;/p&gt;

&lt;p&gt;我心里之前想着既然南大软院的bar可能没有南大cs和ai那么高，觉得以自己的水平应该争取争取能优秀吧，结果发现自己还是太天真了，由于线上夏令营很多学生都采取了海投的策略，导致像我这种rank不算特别特别突出然后又没有什么科研的同学根本没有机会入营，更别提优营了。&lt;/p&gt;

&lt;p&gt;当那天得知这个消息的时候自己有些惊讶，也有些难过，并且决定立马也改变策略，暑假认真准备专业课，然后冲预推免到九月的时候也要海投。可是后来才发现自己又天真了，很多学校夏令营招够了优秀营员以及足够长的waiting list之后便不再进行预推免，比如上交。&lt;/p&gt;

&lt;hr data-content=&quot;充满了焦虑、彷徨、迷茫、消沉的一个夏天&quot; /&gt;

&lt;p&gt;这个暑假其实很消沉。&lt;/p&gt;

&lt;p&gt;保外前途渺茫，看着很多成绩+科研+竞赛样样全能的大佬们早就已经手握好多offer，自己却夏令营变成夏零营，预推免能否入营还依旧是个未知数。&lt;/p&gt;

&lt;p&gt;保内早已错失良机，学校里比较好的实验室比较好的老师已经被立志留本校的同学早早抢去了名额，剩下的实验室还有导师自己其实都不太愿意去。&lt;/p&gt;

&lt;p&gt;此时陷入了一个进退两难的局面。&lt;/p&gt;

&lt;p&gt;暑假里在自己身上出现了一种非常奇怪的状态，仿佛在某一个瞬间，自己突然对很多东西一下子都提不起兴趣了，不想学习，不想玩游戏，不想出去玩，不想社交不想参加饭局。暑假整个人处于一个能量很低气压很低的状态。&lt;/p&gt;

&lt;p&gt;我也一直在想，外校的title，南大的情节，软件学院，专硕，java开发，这些到底值不值得我去花这么多精力和时间去争取？自己研究生阶段到底想要的是什么？&lt;/p&gt;

&lt;p&gt;后来一次偶然的机会在网上了解到了TiDB这个分布式数据库产品还有PingCAP这家很cool的公司，看到数据库，分布式，高并发，存储引擎这些字眼的时候我发现自己逐渐变得兴奋了起来。&lt;/p&gt;

&lt;p&gt;依稀记得这种感觉之前只在我的身上出现过两次，一次是19年冬天学计算机系统看到段页式存储管理，一次是21年春天数据库系统课程上面当老师讲到缓冲池替换算法，并且自己联想到操作系统课程中相应的替换算法的时候，这可能就是之前阿里那位前辈所说的，融会贯通的一点点苗头了吧。&lt;/p&gt;

&lt;p&gt;要不，研究生去做数据库吧？一个大胆的念头在心里产生。&lt;/p&gt;

&lt;p&gt;后来就开始在网上搜集各种相关的前景，比如了解到了蚂蚁金服的OceanBase团队还有华为的Gauss团队都是技术水平极高的团队，也都在做着很cool的产品，虽然也有人说这个行业门槛高，想要做好很难很难，不过在这样的团队工作可以极大提升自己的技术水平，在公司里面这个团队可能短期内并没有去做业务或者做类似王者这种手游挣钱，但是我自己觉得找工作并不能只盯着眼前的起薪，而更应该去看自己到公司的团队里面的成长空间，毕竟同一家公司里面组和组之间的差距可能比公司和公司的差距更大，而我更想去那种技术为导向的组而不是kpi为导向的业务的组。&lt;/p&gt;

&lt;p&gt;本校恰好自己数据库系统的邹兆年老师就是在做数据库系统方面的研究，老师水平也很高，风评也很好，于是便萌发了自己想要跟着这个老师读研的想法，可惜由于已经太晚，老师那个实验室几乎已经招满了人，然后自己几个朋友之前去找这个老师也被婉拒了。&lt;/p&gt;

&lt;p&gt;在假期的尾巴上，和爸爸妈妈沟通了我的想法，他们也表示十分支持我。&lt;/p&gt;

&lt;p&gt;大概9月份开学之后，保研优先级便是&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;优先级&lt;/th&gt;
      &lt;th&gt;课题组&lt;/th&gt;
      &lt;th&gt;对应的研究生生活&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;最高&lt;/td&gt;
      &lt;td&gt;本校数据库组&lt;/td&gt;
      &lt;td&gt;在这个领域继续进行深耕，研究生要研究源码，要尝试自己做改进，认真做课题，然后毕业奔着几个大厂的数据库团队求职&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;其次&lt;/td&gt;
      &lt;td&gt;南软软件工程组&lt;/td&gt;
      &lt;td&gt;由于是软件工程，所以拓展了技术广度，前端后端等等技术要争取样样精通，之后帮着导师做项目，自己刷实习，找后端前端这种业务开发类型的工作&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;最次&lt;/td&gt;
      &lt;td&gt;本校放羊组&lt;/td&gt;
      &lt;td&gt;导师和实验室不怎么管，实验室研究的方向和找工作的方向也毫无关系，然后自己去研究自己感兴趣的领域，自己去刷题刷面经准备秋招找工作&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;这次走之前爸爸跟我说，虽然爸爸不懂你们的专业，但是研究生一定一定要选一个自己喜欢的行业啊，如果不喜欢的话会很苦恼的。&lt;/p&gt;

&lt;hr data-content=&quot;柳暗花明又一村&quot; /&gt;

&lt;p&gt;开学之后便着手开始准备面试，投预推免，然后也一边准备去找本校的邹老师。&lt;/p&gt;

&lt;p&gt;九月的第一个好消息是，把消息发给邹老师的时候老师约了我面谈，面谈的时候老师第一句话就是，你怎么和成绩单上面的照片不一样了（那个照片是18年入学拍的丑死了……）,然后又说老师记得我上课时候很认真努力，最后成绩也很不错，老师非常耐心地给我介绍了他的研究方向，最后也很爽快地答应了我让我入组。&lt;/p&gt;

&lt;p&gt;后来陆陆续续收到浙大初审没过，哈深初审没过的拒信，不过那已经关系不大了。&lt;/p&gt;

&lt;p&gt;九月的第二个好消息是突然收到了南大初审通过准备面试的邮件，一时不知道是高兴还是什么情绪，终于之前的梦校如今和我只差一步之遥了，机会就摆在面前还是要试一下，先把选择权握在自己手上。&lt;/p&gt;

&lt;p&gt;于是便又开始纠结工大or南大？算了准备面试先。&lt;/p&gt;

&lt;p&gt;另一个转折点是在南软面试的时候，当我辛辛苦苦准备了计算机专业课基础知识的时候，发现那里只是考了八股文，自己准备了好久的DBMS中的缓冲池实现这个项目，面试的老师根本不care，还中途打断问我究竟做没做过什么项目，可能在那个软工的老师心里，只有做一个什么app或者上线一个什么什么系统才能称得上是一个项目吧。&lt;/p&gt;

&lt;p&gt;面试体验极差，同时也让我明白了CS到SE其实已经算是跨专业，CS这边的东西至少那个老师看不上，而那边的项目在我眼里也没有数据库的项目更感兴趣。同时之前对于那个学院的各种担忧，比如一些网上看到的黑料，还有一些南大软院那里的朋友都和我说快逃等等诸如此类情感的在一个瞬间爆发了。&lt;/p&gt;

&lt;p&gt;虽然几乎已经确定想要留在哈尔滨了，但还是多多少少有点不甘心也在最后还是有点纠结，后来第二天晚上和任一通了一个多小时的电话，也和家里人打了好久电话，最终终于定下来要留在这里了，在这里继续在自己喜欢的方向进行深耕。&lt;/p&gt;

&lt;p&gt;再后来，在填系统前一天收到了南大软院的offer，然后自己很坚定地放弃了，也给那边的老师发了很长的一段道歉信，鸽掉那边的老师也真的挺不好意思的（因为那个老师人真的超好真的真的特别不好意思）。&lt;/p&gt;

&lt;p&gt;后来28号填系统报志愿，一个非常幸运的事情是，之前本校实验室只给我分配了一个专硕的名额，后来某个占着学硕名额的buaa的同学最后鸽掉了，我顺位最终拿到了0812学硕名额，也算是一个那天很幸运很开心的一件事情了。&lt;/p&gt;

&lt;p&gt;在后来就是看着朋友圈和空间里面大家在晒去向和录取结果，清华的，北大的，清深的，上交的，浙大的，原本以为自己继续留在这里会不甘心，以为自己会像高考后那样很羡慕很眼红，但是惊奇的发现自己好像并没有，心里很踏实很平静。&lt;/p&gt;

&lt;p&gt;这里有自己很喜欢的方向，也有自己很喜欢的导师，实验室也是学校里面的头牌实验室之一，这里还有自己熟悉的环境，也有好多本科时期很好的朋友。&lt;/p&gt;

&lt;p&gt;记得之前白鹭在朋友圈发过的一篇小作文里面说的一句“很难比较，每天坚持做三道解析几何，和经历失眠和焦虑后做出一次勇敢的选择，哪一个努力了更多”&lt;/p&gt;

&lt;p&gt;可能经历了2021一整年的失眠和焦虑，最后终于知道了自己想要的是什么，也在这个过程中成长了许多。&lt;/p&gt;

&lt;h3 id=&quot;下个阶段&quot;&gt;下个阶段&lt;/h3&gt;

&lt;p&gt;保研结束之后，进了组，分了工位，然后邹老师还安排了一位特别热心负责技术水平也高的研二学长带我去完成一些基础可以上手的任务。&lt;/p&gt;

&lt;p&gt;（插一句很有意思的事情，其实在填系统前一天晚上我很焦虑就给导师打了电话，其中向导师寻求大四还有研究生阶段的规划路线的建议的时候，老师给我的规划和我设想的理想中的研究生生活几乎一致，老师还推荐了一本书给我让我这学期学一下，很巧的是当我一搜发现，那本书之前就已经进了我当当网的购物车！）&lt;/p&gt;

&lt;p&gt;下个阶段还要继续加油努力啊！还有好多好多东西要去学，还有好多好多坑还没有填。&lt;/p&gt;

&lt;h3 id=&quot;写在最后&quot;&gt;写在最后&lt;/h3&gt;

&lt;p&gt;2021这一年对于我来说应该是非常非常特殊的一年，十分感谢一直在我身后支持我的爸爸妈妈，也十分感谢一直在我身边以各种方式默默陪着我的朋友们，有的在我非常迷茫的时候被我一通电话拉出来一打就是好久，有的朋友哪怕自己也在考研也愿意听我叨叨自己的焦虑并且也一点都没有觉得我是在凡尔赛，有的朋友总是在食堂吃完饭之后一起在操场遛弯聊天，也有的被我拉到学校旁的小清吧喝酒，也还有一些其他专业的朋友虽然不是太懂计算机专业里面的知识，但是也以其他的方式给予我源源不断的能量，比如有的朋友在我最低沉的那段日子里时不时地就拉我出来散心，拉我出来享受美食，也有的朋友关心我的去向和想法，也有的在那段日子里和我一同分享读书的心得和喜悦。在我最最煎熬的日子里（可能有时候我不愿意将太多负面情绪传递出来所以可能平时并不明显），你们的每一点关心和共情，或者是在我最低沉的时候给我传递来的一点点快乐和一点点能量，我都会记得，真的真的十分感谢。&lt;/p&gt;</content><author><name>Jeremy Yang</name></author><category term="view" /><summary type="html">一次心血来潮的阶段性总结</summary></entry></feed>